---
title             : "Beyond *p*-values: Utilizing Multiple Methods to Evaluate Evidence"
shorttitle        : "Multiple Methods"

author: 
  - name          : "Kathrene D. Valentine"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "210 McAlester Ave, Columbia, MO 65211"
    email         : "Katy.valentine3@gmail.com"
  - name          : "Erin M. Buchanan"
    affiliation   : "2"
  - name          : "John E. Scofield"
    affiliation   : "1"
  - name          : "Marshall T. Beauchamp"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "University of Missouri"
  - id            : "2"
    institution   : "Missouri State University"
  - id            : "3"
    institution   : "University of Missouri - Kansas City"

author_note: >
  Kathrene D. Valentine and John E. Scofield are Ph.D. candidates at the University of Missouri. Marshall T. Beauchamp is a Ph.D. candidate at the University of Missouri - Kansas City. Erin M. Buchanan is an Associate Professor of Quantitative Psychology at Missouri State University. 
  
  KDV and EMB decided on the study design. MTB helped in initial data analysis. JES and EMB programmed the R code for simulation, analysis, and graphics. KDV wrote the first draft of the manuscript, which EMB put into R markdown. All authors critiqued and edited the manuscript, and all authors approved the submitted version of the manuscript. 

abstract: >
  Null hypothesis significance testing is frequently cited as a threat to the validity and reproducibility of the social sciences. While many individuals suggest we should focus on altering the *p*-value at which we deem an effect significant, we believe this suggestion is short-sighted. Alternative procedures (i.e., Bayesian analyses and Observation Oriented Modeling; OOM) can be more powerful and meaningful to our discipline. However, these methodologies are less frequently utilized and are rarely discussed in combination with NHST. Herein, we discuss the historical roots, procedures, and assumptions of three methodologies (NHST, Bayesian Model comparison, and OOM), then compare the possible interpretations of three analyses (ANOVA, Bayes Factor, and an Ordinal Pattern Analysis) in various data environments using a simulation study. The simulation generated 20,000 unique datasets which varied sample size (*N*s of 10, 30, 100, 500, 1,000), and effect sizes (*d*s of 0.10, 0.20, 0.50, 0.80). Through this simulation, we find that changing the threshold at which *p*-values are considered significant has little to no effect on conclusions. Further, we find that evaluating multiple estimates as evidence of an effect can allow for a more robust and nuanced report of findings. These findings suggest the need to redefine evidentiary value and reporting practices.

  
keywords          : "null hypothesis testing, p-values, Bayes Factors, Observation Oriented Modeling, evidence"

bibliography      : ["alt nhst.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r include = FALSE}
library("papaja")
#devtools::install_github("trinker/numform")
library(numform)
```
Recent events in psychological science have prompted concerns within the discipline regarding research practices and ultimately the validity and reproducibility of published reports [@Etz2016; @Lindsay2015; @OpenScienceCollaboration2015; @VanElk2015]. One often discussed matter is over-reliance, abuse, and potential hacking of *p*-values produced by frequentist null hypothesis significance testing (NHST), as well misinterpretations of NHST results [@Gigerenzer2004; @Ioannidis2005; @Simmons2011]. We agree with these concerns and believe that many before us have voiced sound, generally accepted opinions on potential remedies, such as an increased focus on effect sizes [@Cumming2008; @Lakens2013; @Maxwell2015; @Nosek2012]. However, other suggestions have been met with less enthusiasm, including a recent article by @Benjamin2017 advocating that researchers should begin thinking only of *p*-values less than .005 as "statistically significant", thus changing $\alpha$ levels to control Type I error rates. Additionally, @Pericchi2016 promote the use of fluctuating $\alpha$ levels as a function of sample size to assist with these errors. We argue it is not the *p*-value that needs to be rethought when seeking evidence, but rather what that *p*-value can tell you in relation to other indicators. While NHST and *p*-values may have merit, researchers have a wealth of other statistical tools available to them. We believe that improvements may be made to the sciences as a whole when individuals become aware of the tools available to them and how these methods may be used in combination to strengthen understanding and conclusions. These sentiments have been shared by the American Statistical Association who recently held a conference focusing on going beyond NHST, expanding their previous stance on *p*-values [@Wasserstein2016]. 

Therefore, we undertook this project to begin to let researchers see the similarities and differences both within the methodological design, as well as within the interpretations of statistics as meaningful. Herein, we have chosen three methodologies to focus on: NHST, Bayes Factor comparisons, and Observation Oriented Modeling. These three approaches will be compared via simulated data using a repeated measures design with a Likert-type scale as the outcome variable. The aims of this study will be to discuss the conclusions that these three methods would make given the same data, and to compare how often these methodologies agree within different data environments (i.e. given different sample sizes and effect sizes). We hope that by discussing these methodologies in terms of a simple statistical analysis researchers will be able to easily compare and contrast methodologies. For this discussion, it is important to understand their historical background, procedural steps, and limitations, which are outlined below. After this discussion, we describe a simulation study comparing methodologies and $\alpha$ criteria, and end with a potential implications for researchers.


# Null Hypothesis Significance Testing

## History

Many attribute the frequentist NHST procedure to Ronald A. Fisher [@Fisher1932]. However, Fisher's ideas are a far cry from the NHST procedure implemented today. Fisher believed in creating one "null" hypothesis, which he described as a hypothesis to be "nullified", or shown incorrect, not as a zero-difference hypothesis [@Lehmann2011]. He also believed that the use of any omnibus level of significance showed a "lack of statistical thinking" [@Gigerenzer2004a]. He instead believed we should report the exact significance value of a test and let others make their own decision about the claims, which is more in line with the typical reporting recommendations provided by the American Psychological Association [@AmericanPsychologicalAssociation2010]. Fisher spoke of this work to William Gosset, the man who created the Student's *t*-test and contributed work on the correlation coefficient [@Lehmann2011]. Gosset in turn discussed the idea of an alternative hypothesis, a piece not included in Fisher's procedure, with decision theorist Egon Pearson.

From this discussion, Egon Pearson and Jerzy Neyman created Neyman-Pearson decision theory. This theory consists of two hypotheses (i.e., null and alternative) and a binary decision criteria [i.e., significant or not, @Lehmann1993]. However, this procedure created the possibility of researcher decision errors [@Dienes2008]. A researcher may falsely reject the null hypothesis (Type I error, $\alpha$) or falsely fail to reject the null (Type II error, $\beta$). $\alpha$ levels set the binary decision criteria, which are used as the critical *p*-value for hypothesis testing (i.e., *p* < .05), and are thus seen as evidence to reject the null hypothesis. $\beta$ and power are inherently linked, as the likelihood of finding a true effect increases when beta decreases [@Maxwell2004]. Although $\alpha$ values can be chosen to be quite small, and methods can decrease $\beta$ values as well, a researcher can never know if they have made the correct decision, or a decision error. Thus, Neyman and Pearson clearly state that a hypothesis should not be blindly supported based solely on the estimates of one statistical test, and that replication and reproduction of results are imperative. The recent work of the @OpenScienceCollaboration2015 has also highlighted the need for replication studies and interpretation of results in an appropriate context. Additionally, Neyman and Pearson emphasized that use of set $\alpha$s and $\beta$s is illogical and sought instead for researchers to adjust their analysis to the needs of the particular task at hand [@Gigerenzer2004].

## Typical NHST Procedure

Neither Fisher's hypothesis testing, nor Neyman-Pearson decision theory quite match the NSHT procedure as it is taught and applied today. Psychologists have largely adopted an amalgamation of the two approaches. Here, we attempt to outline what we believe is the most appropriate way to carry out the traditional NHST procedure, although we note that this set of steps is not necessarily how researchers carry out the procedure in practice:

  1) Create two hypotheses, one to be "nullified" and one "alternative" hypothesis. Within this repeated measures framework, most researchers would define a null hypothesis ($H_0$) that indicates of all three time points are equal. The alternative hypothesis ($H_A$) would then be that the means of all three time points are not equal in some form. These can be operationalized in our example data as follows:

$$
\begin{aligned}
  H_0: \mu_1 = \mu_2 = \mu_3 \\
  H_A: \mu_1 \neq \mu_2 \neq \mu_3
\end{aligned}
$$
  2) Select an $\alpha$ level that is appropriate given the context of your research, your analysis plan, and your research question, and do not blindly adopt an omnibus critical *p*-value [@Lakens2017].

  3) Compute your given analysis and identify the corresponding *p*-value. If your *p*-value is less than the chosen $\alpha$, reject the null hypothesis and state that there appear to be differences between your means; however, if your *p*-value is greater than or equal to the value selected, do not reject the null hypothesis, and state that a difference between the means could not be supported.
  
While the NHST procedure itself gives us testable models, the specific analysis used to test these models here, the repeated measures ANOVA with 3 levels, requires some additional assumptions that must be met before an analysis is begun [@Tabachnick2012]. Data need to have no missing values and no outlying or influential observations. Data must have a normal sampling distribution, be linearly related, and have independent errors. Depending on the statistical test, data must also be checked for equal variances, sphericity, and additivity. These assumptions can be checked and, if necessary, corrected for; however, violations of these assumptions can lead to inaccurate decisions and attenuated power. 

While this approach is widely used, there are many limitations associated with it. First, this method can be sensitive to violations of the stated assumptions, and especially, if the sample size is not large enough to create a normal sampling distribution [@Tabachnick2012]. Even if assumptions are met, or nonparametric tests are implemented, this methodology does not allow a researcher to state anything about the absence of an effect (i.e., no true differences). Through traditional NHST, one can only discuss evidence regarding the alternative hypothesis; one can never support the null hypothesis through this procedure. Given the recent findings regarding reproducibility, showing support for the absence of an effect is even more crucial [@Bakker2012; @Lakens2017a]. 

# Bayes Factors

## History

Thomas Bayes was a statistician and Presbyterian minister whose works are still influential today [@Bellhouse2004]. Bayes' theorem solved the inverse probability problem, namely that through the frequentist approach, one can only know the probability of data existing given a hypothesis being true, never the probability of a hypothesis being true given that the data exist [@Dienes2008]. Bayes' theorem allows one to calculate the probability of a hypothesis given some data (posterior belief) by using how probable one believes the hypothesis to be before data was collected (prior belief) and how probable one believes the data to be given one's hypothesis (likelihood). Thus, with his theorem, researchers are able to update (through the use of the likelihood) our initial beliefs (our prior) given some data [@Gelman2004]. Pierre-Simon Laplace pioneered Bayesianism and advocated for a broader interpretation of this theorem [@DeLaplace1774]. The use of Bayesian statistics has been suggested as an NHST alternative [@Dienes2014; @Wagenmakers2007], but this approach has largely been undervalued in favor of frequentist methods as, until recently, Bayesian analysis required considerable computational effort. However, today we possess the technology necessary to conduct Bayesian analyses efficiently. While open source software, such as *R* and JASP, require minimal learning to be able to effectively operated [@Morey2015b], researchers will need to invest more effort to understanding the focus and interpretation of Bayes Factor (BF) comparisons as they differ from traditional NHST.

The Bayesian framework can be viewed as a continuum, with objective Bayesian analyses on one end, and subjective Bayesian analyses on the other [@Press2002]. While this topic could lend itself to its own manuscript, here we will simply summarize the two endpoints, and discuss where our analysis may be perceived to fall on the line. Objective Bayesian analysis is closest to frequentist theory, as priors are set to be as uninformative as possible to allow little, if any, influence on the estimates and distribution of the posterior; thus, the data is allowed to maximally effect the posterior distribution. On the other end, subjective Bayes analyses include rigorously informed priors so that current knowledge can play a large role in the posterior. Our current analysis splits these two; we do not utilize completely uniformed (objective) priors, as we can adjust for basic knowledge of the constraints of our data type. Given the usual lack of information about underlying distributions, a wider band of inclusion was used for prior information. The *BayesFactor* package [@Morey2015b] assists greatly in the choice of prior and is especially user-friendly for applied researchers, as it makes use of recommended default priors that have been chosen to be safe to assume under a broad range of data and topics [@Rouder2012; @Rouder2009]. Instead of conventional *F*, *t*, and *p*-values, a ratio of the likelihood of the alternative model to the null is report, usually $BF_{10}$. For instance, $BF_{10}$ = 20 would indicate that the effects model is favored 20 to 1 over the null model. Conversely, if the $BF_{10}$ were 0.10, the null model is favored 10 to 1 over the effects model. 

## Typical Procedure

The procedure behind BF comparisons requires two steps. 

  1) One must design two models for the data. For our purposes, the first of these models will be the null model, which states that there are no differences between means ($\mu$; i.e. all of our observed values $X_{i}$, regardless of which time point they were assessed at $X_{ij}$, arise from a normal distribution *N* with some mean $\mu$ and variance $\sigma^2$). The second model for these analyses is the effects model, which states that each mean ($\mu$) is allowed to be different from the grand mean by some amount ($\alpha$; as we now have observations being drawn from three potential normal distributions, all of which may have a different mean value, but the same variance). These can be operationalized as follows:

$$
\begin{aligned}
  H_0: X_{ij} \sim N(\mu, \sigma^2) \\
  H_A: X_{ij} \sim N(\mu + \alpha_i, \sigma^2)
\end{aligned}
$$
  In designing these models, one must choose the prior distributions that are believed to describe the data. Reasonable expectancies of where the data lie should be incorporated in this decision based on previous research into the studied phenomena [@Rouder2012]. 
  
  2) Analyze the data given the selected priors and models. Consider the BF and use the $BF_{10}$ as evidence of how one should update their beliefs about the models.

Based on the flexibility of the analysis, the only assumption that needs to be made is that data exists such that two competing, plausible models with different constraints may be specified. 

Bayesian inference improves upon the traditional frequentist point of view by allowing not only a clear interpretation of the evidence provided by the data, but also the ability to speak in favor of the null hypothesis. It is important to note that while previous work has indicated that *p*-values and BF largely agree on which hypothesis should be supported, they differ in the strength of that conclusion, especially when *p*-values were slightly lower than $\alpha$ [i.e., .05 to .01; @Wetzels2011]. However, some limitations do arise in this paradigm. Bayesian analyses require the researcher to take an active role in the choice of prior distributions for the phenomenon they are modeling, and this decision can take some effort to fully understand; however, in the meantime, there are packages such as *BayesFactor* that allow the researcher simple default options that can readily lend themselves to many research areas with little fear of being outrageous specifications. Further, unlike NHST, Bayesian analyses do not necessarily control long-run error rates, as the focus is on updating current model beliefs. Another concern that many researchers have is that these analyses are necessarily sensitive to prior choice. However, research has shown that the choice of priors has essentially no effect on conclusions when sufficient data has been collected as the priors give way to the weight of the data [@Rouder2012; @Klugkist2007] and when reasonable priors are considered, data are only mildly sensitive to these [@Haaf2017]. Finally, many believe Bayesian analysis to be too computationally intensive to complete. However, many simple programs, packages, and tutorials exist to help ease the transition from frequentist to Bayesian analysis [@Morey2015b; @JASPTeam2017; @Kruschke2014].

# Observation Oriented Modeling

## History

James Grice argues that our problems as a science go beyond use of NHST and extend into the philosophical ideas underpinning our research. Therefore, he developed a new paradigm called Observation Oriented Modeling [OOM, @Grice2011; @Grice2012; @Grice2014]. He reasons that by viewing psychology through the lens of realism, instead of positivism, we should be able to properly and effectively conduct research and analyze data. In contrast to positivism (i.e., which is solely concerned with finding an effect, not with how the effect occurred), realism is the belief that effects conform to their cause and that given the correct models of these processes we can begin to understand our reality. By viewing science as knowing nature through its causes, we can use Aristotle's four causes (material, efficient, formal, and final) to think in terms of structures and processes in order to explain phenomena. Switching to this philosophy allows for techniques that match the daily activities of social scientists in their endeavors to unravel the story of how humans operate. Using OOM, a researcher does not focus on population parameters and the various assumptions underlying statistical tests (e.g., random sampling, normality, homogeneity of population treatment differences, etc.). Instead, the researcher alternatively focuses on observations at the level of the individual.

Generally speaking, this approach can handle any type of data, including ordinal rankings and frequency counts, as all analyses are calculated in the same general fashion [see @Valentine2013 for an example]. This simplicity occurs because OOM works on the deep structure of the data. Through observational definition, the program separates these units into binary code. Deep structures can be arranged to form a matrix, which can then be manipulated via matrix algebra, binary Procrustes rotation, and other operations to investigate the data. The most important values from any OOM analysis are the PCC (percent correct classification) values. These values represent the summation of how well an individual’s responses matched the stated or expected pattern or, in the case of causal modeling, how many of the individual’s conformed to a given cause. Complete matches are the proportion of observations that match the researcher-designated pattern on all dimensions. For example, in a three-level Ordinal Pattern Analysis (OPA), a person would be tallied as a "complete match" if the ordinal pattern of his/her data matched the expected ordinal pattern across all three levels. Imagine we have set a pattern that designates that time 1 responses should be less than time 2 which should be less than time 3. Given the data for two hypothetical individuals in Table \@ref(tab:oompattable), we can see that person A matched the pattern completely, and therefore would be counted in the PCC value. However, while person B matched the first part of our pattern (time 1 less than time 2), they did not match on the third point of our pattern (time 2 less than time 3); thus, they would not be counted in the PCC value.  The PCC value replaces all of the conventional values for effect size used in statistical analyses. 

The analysis we focus on here (OPA) does not form any type of linear or nonlinear equation or regression, but simply looks for those individuals who match the expected ordinal pattern [@Grice2015]. The main point of the analysis, then, is to see how many people fit the expected pattern which is based on a causal theory. If all causes are accounted for in the study and observations have been made with sufficient precision and accuracy, then 100% of the persons should fit the expected pattern; otherwise, a lower PCC value will be expected and it is up to the researcher to determine how high a PCC must be in order to support an inference to the causal mechanism. 

```{r oompattable, echo = FALSE, results = 'asis'}

oomtable = matrix(NA, nrow = 3, ncol = 4)
oomtable[1, ] = c("Individual", "Time 1", "Time 2", "Time 3")
oomtable[2, ] = c("A", 3, 4, 5)
oomtable[3, ] = c("B", 4, 5, 2)

apa_table(oomtable,
          align = c("l", rep("c", 3)), 
          caption = "OOM Ordinal Pattern Analysis Example")
```

In OOM, *p*-values are no longer utilized [@Grice2011]. As a secondary form of reference value, a chance value (*c*-value) is obtained, which is a type of randomization test in which the researcher determines the number of randomized trials for the test (e.g. 1,000 or 5,000 randomized versions of actual observations). This procedure is akin to permutation tests, where the original data is shuffled a number of times to create comparable data sets. These randomized data sets are then compared to the designated pattern. If the randomized data sets fit the pattern as well as or better than the actual data does, the *c*-value will be high (close to 1). Low *c*-values (close to 0) indicate a pattern of observations that is improbable (i.e., unlikely produced by chance) when compared to randomized versions of the same data. Although low *c*-values, like low *p*-values, are desirable, *c*-values do not adhere to a strict cut-off and should be considered a secondary form of confirmation for the researcher that their results are distinct. 

## Typical Procedure

The OPA is analogous to repeated measures ANOVA and contains two steps.

  1) Designate the expected ranked pattern: each variable as being higher, lower, or equal to the other variables. For instance, for our analyses we defined the following pattern of individual responses $X_i$, whereby the first time point should be less than the second time point which should be less than the third time point. This pattern can be operationalized as follows:

$$
  X_{i_1} < X_{i_2} < X_{i_3}   
$$

  2) Analyze the data using the OPA. Consider the PCC and *c*-values in light of the data and use your best judgment as to whether or not the data conform to the expected pattern. This analysis only requires the assumption that the data exists such that a pattern may be designed.

As with all of these methodologies, limitations do exist. This approach is largely concerned with patterns of responses, not with magnitudes of differences, which may be an integral piece of information to some researchers. Unlike all approaches mentioned before, we do not discuss the probability of some data given our hypothesis here, and instead focus on the observed responses of the individual and how it may or may not behave as expected. Finally, similar to the Bayesian analysis, long-run error rates are not discussed in this methodology.

# A Simulation Study

## Simulated Data

```{r simulation-code, eval=FALSE, include=FALSE}
ptm = proc.time()

####cohen's d dependent t differences####
d.deptdiff = function (mdiff = 0, sddiff = 1, n = 10, a = .05) {
  d = mdiff / sddiff
  se = sddiff / sqrt(n)
  t = mdiff / se
  ncpboth = conf.limits.nct(t, (n-1), conf.level = (1-a))
  dlow = ncpboth$Lower.Limit / sqrt(n)
  dhigh = ncpboth$Upper.Limit / sqrt(n)
  Mlow = mdiff - se*qt(a/2, n-1, lower.tail = FALSE)
  Mhigh = mdiff + se*qt(a/2, n-1, lower.tail = FALSE)
  p = pt(abs(t), n-1, lower.tail = F)*2
  
  output = list("d" = d, 
                "dlow" = dlow, 
                "dhigh" = dhigh, 
                "Mlow" = Mlow, 
                "Mhigh" = Mhigh)
  return(output)
  
}

###oom function####
OOM <- function(x, y, xlev = NULL, ties.method = "first", ambiguous.error=FALSE) {
  # Computes main OOM results; this is the central function
  #
  # Args:
  # x: the vector to be conformed to the target vector,
  #    ie, consisting of observed data, the "as-is" pattern,
  #    can be integer, numeric, or factor (max. 30 unique values)
  # y: the target vector consisting of the expected ("true") pattern
  #    can be integer, numeric, or factor (max. 30 unique values)
  # xlev: levels of the x variable
  # ties.method: for breaking ties when conforming matrices. Allowed value:
  #              "random": breaks ties randomly to one class
  #               "first": break ties to most frequent class
  #               "last": allowed, but not recommended
  # ambiguous.error: Shall ambiguous observations be classified as error?
  #
  # Returns:
  # Most important OOM results: PCC, conforming matrix, vector of predicted
  #                             classes
  # Error handling
  allowed_ties_methods <- c("random", "first", "last")
  if (!(ties.method %in% allowed_ties_methods)) stop("unknown ties.method.\n")
  sample_size <- length(x)
  # Compute Deep Structure matrices
  Xds <- ds(x, lev = xlev)
  Yds <- ds(y)
  # init vector for classification results (correct/false/ambiguous) for each
  # observation (case)
  classification <- vector(length = sample_size)
  # Frequencies of events (where indicator variable equals 1)
  Ybaseline <- colSums(Yds)
  Xbaseline <- colSums(Xds)
  # Sort Deep Structure of y according to a priori if ties.method="first",
  # i.e. choose in case of ambiguity most frequent class
  if (ties.method == "first") Yds <- Yds[, order(Ybaseline, decreasing = TRUE)]
  # Normalizing for Pseudoinverse
  iXbase <- 1 / Xbaseline
  # Correction for events with 0 frequency
  iXbase[Xbaseline == 0] <- 0
  # Projection (analog to Grice's "Binary Procustres Rotation Matrix")
  # P is the normalized matrix
  P <- diag(iXbase) %*% t(Xds) %*% Yds
  rownames(P) <- colnames(Xds)
  # Conforming Matrix
  Yconf <- Xds %*% P
  # Identify ambigious cases
  yamb <- apply(Yconf, 1, nomax)
  Amb <- which(yamb >= 2)
  # Conform the events, i.e., create vector of precicted classes
  yconf <- factor(colnames(Yds)[max.col(Yconf, ties.method = ties.method)],
                  levels = colnames(Yds))
  # True Events
  ytrue <- factor(colnames(Yds)[max.col(Yds)], levels = colnames(Yds))
  
  x <- factor(colnames(Xds)[max.col(Xds)], levels = colnames(Xds))
  # Calculation of PCC (accuracy)
  PCC <- mean(yconf == ytrue)
  # Calculation of PCC (accuracy), ambiguous
  yconfa <-  colnames(Yds)[max.col(Yconf, ties.method = ties.method)]
  yconfa[Amb] <- "ambiguous"
  yconfa <- factor(yconfa, levels = c(colnames(Yds), "ambiguous"))
  levels(ytrue) <- c(levels(ytrue), "ambiguous")  # same levels for both vectors
  PCCAmb <- mean(yconfa == ytrue)
  ytrue <- droplevels(ytrue)
  
  # Override PCC if   ambiguous.error=TRUE
  if (ambiguous.error) PCC <- PCCAmb
  # Conforming strength
  CSI <- apply(Yconf, 1, max)
  CSI_mean <- mean(CSI, na.rm = T)
  # Baseline PCC
  PCCbase <- max(Ybaseline)/sum(Ybaseline)
  # Conforming Table
  Conforming_matrix <- table(x, yconf)
  ambiguity <- table(x[yamb > 1])
  Conforming_matrix <- cbind(Conforming_matrix)
  # What to return
  return(structure(list(Xds = Xds, Yds = Yds, P = P, Yconf = Yconf, yconf = yconf,
                        PCC = PCC, PCCbase = PCCbase, PCCAmb=PCCAmb, CSI = CSI,
                        CSI_mean = CSI_mean,
                        Amb = Amb, Conforming_matrix = Conforming_matrix,
                        ytrue = ytrue,
                        x = x, y = y,
                        sample_size = sample_size, ties.method = ties.method, 
                        ambiguous.error=ambiguous.error),
                   class = "OOM"))
}
# Compute number of maxima 
nomax <- function(x) {
  # Helper function: calculation of number of maxima
  # Arg:
  # vector (numeric)
  #
  # Returns:
  # Number of maxima (scalar)
  mx <- max(x)
  nmx <- sum(x == mx)
  return(nmx)
}

# Compute "deep structure" matrices, ie., indicator matrices
ds <- function(x, lev = NULL)
{
  # Convert Matrix to Deep Structure (ds), i.e. Indicator Matrix of Events
  # where x  = raw matrix to be converted to deep structure; lev = names of levels
  if (any(is.na(x)))    stop("Currently NA not supported")
  if (!is.factor(x))
  {
    if (is.null(lev))
    {
      if (is.numeric(x))
      {
        if (typeof(x) != "integer")
          stop("Currently only discrete values of x supported ",
               "(integer or factor). Consider binning,",
               "Ranking, or conversion to integer.")
        lev <- c(min(x):max(x))
      } else lev <- unique(x) # in case of numeric values (not integer)
    }
    x <- factor(x, levels = lev)
  }
  if (length(lev) >= 30)
    warning("Number of distinct events >= 30. Consider Binning?")
  xds <- model.matrix(~x - 1)
  attr(xds, "assign") <- NULL
  attr(xds, "contrasts") <- NULL
  colnames(xds) <- levels(x)
  return(xds)
}
# predict method for OOM
predict.OOM <- function(oom, newdata)
{
  # predict method for OOM
  if (!missing(newdata))
    Xds <- ds(newdata, lev = colnames(oom$Xds)) else Xds <- oom$Xds
    posterior <- Xds %*% oom$P
    
    class <- factor(colnames(posterior)[max.col(posterior, ties.method = oom$ties.method)],
                    levels = colnames(posterior))
    
    # Handling of ambiguous observation
    if (oom$ambiguous.error)
    {
      yamb <- apply(posterior, 1, nomax)
      Amb <- which(yamb >= 2)
      levels(class) <- c(levels(class), "ambiguous")
      class[Amb] <- "ambiguous"
    }
    
    return(list(posterior = posterior, class = class))
}
# print method for OOM
print.OOM <- function(oom)
{
  # print method for oom
  cat("Observation Oriented Modelling \n")
  cat("Conforming Table :\n")
  print(oom$Conforming_matrix)
  cat("PCC Value: ", oom$PCC, "\n")
  cat("PCC Baseline : ", oom$PCCbase, "\n")
}
# summary method for OOM
summary.OOM <- function(oom)
{
  # summary method for oom
  cat("Observation Oriented Modeling \n\n")
  cat("Conforming Table :\n")
  print(oom$Conforming_matrix)
  cat("\n")
  cat("Confusion Matrix :\n")
  ytrue <- factor(colnames(oom$Yds)[max.col(oom$Yds)], levels = colnames(oom$Yds))
  print(table(ytrue, oom$yconf))
  cat("PCC Value: ", oom$PCC, "\n")
  cat("PCC Baseline : ", oom$PCCbase, "\n")
  cat("PCC Ambiguous as Error: ", oom$PCCAmb, "\n")
  cat("OOM Accuracy Gain : ", (oom$PCC/oom$PCCbase), "\n\n")
  cat("Projection Matrix: \n")
  print(oom$P)
}
# compute chance (c) value for OOM 
OOMc <- function(oom, B = 1000, alpha = 0.95)
{
  # Calculation of c-Value
  
  # Observed PCC
  PCCt = oom$PCC
  
  # Vector of permutated data PCC
  PCCp <- length(B)
  
  n <- nrow(oom$Xds)
  ap <- (1 - alpha)/2
  Yds <- oom$Yds
  ytrue <- max.col(Yds)
  
  for (i in 1:B)
  {
    # Permutation sample (x)
    bs <- sample(1:n)
    # OOM Analysis
    Xbs <- oom$Xds[bs, ]
    Xbaseline <- colSums(Xbs)
    iXbase <- 1/Xbaseline
    iXbase[Xbaseline == 0] <- 0
    yconf <- (Xbs %*% diag(iXbase) %*% t(Xbs) %*% Yds)
    yhat <- max.col(yconf, ties.method = oom$ties.method)
    
    # Handling of ambiguous observation
    if (oom$ambiguous.error)
    {
      yamb <- apply(yconf, 1, nomax)
      Amb <- which(yamb >= 2)
      yhat[Amb] <- 0
    }                   
    
    PCCp[i] <- mean(yhat == ytrue)
  }
  
  PCCps <- sort(PCCp)
  
  # c Value
  cvalue <- mean(PCCp >= PCCt)
  #cat("PCC : ", PCCt, "\n")
  #cat("Number of Permutations: ", B, "\n")
  #cat("c Value: ", cvalue, "\n\n")
  
  #cat("PCC Permutation Interval, alpha=", alpha, "\n")
  #cat("Lower Bound: ", PCCps[floor(B * ap)], ", Upper Bound: ",
  #    PCCps[ceiling(B *(1 - ap))], "\n")
  return(list(PCCt = oom$PCC, PCCp = PCCp, B = B, chancevalue = cvalue))
}

# perform cross validation (cv) for OOM results
OOMcv <- function(oom)
{
  # Leave-one-out Cross Validation for oom
  y <- factor(colnames(oom$Yds)[max.col(oom$Yds)], levels = colnames(oom$Yds))
  x <- factor(colnames(oom$Xds)[max.col(oom$Xds)], levels = colnames(oom$Xds))
  xlev <- levels(x)
  n <- length(x)
  PCCcv <- numeric(n)
  yt <- y
  
  # Handling of ambiguous observation
  if (oom$ambiguous.error) levels(yt) <- c(levels(yt), "ambiguous")  
  # Looping
  for (i in 1:n)
  {
    ommi <- OOM(x[-i], y[-i], xlev = xlev, ties.method=oom$ties.method, ambiguous.error=oom$ambiguous.error)
    pommi <- predict(ommi, x[i])
    PCCcv[i] <- (pommi$class == yt[i])
  }
  
  cat("PCC Value: ", oom$PCC, "\n")
  cat("PCC Baseline : ", oom$PCCbase, "\n")
  cat("PCC Cross Validated: ", mean(PCCcv), "\n")
  return(list(PCCcv = mean(PCCcv), PCCcvv = PCCcv))
}
####end oom stuff

####simulations for data####
library(mvtnorm)
library(data.table)
library(ez)
library(reshape)
library(PMCMR)
library(BayesFactor)
library(MBESS)
##rmvnorm(n, mean = rep(0, nrow(sigma)), sigma = diag(length(mean)),
##        method=c("eigen", "svd", "chol"), pre0.9_9994 = FALSE)

##n = number of observations, we will want to rotate through
##10, 30, 100, 500, 1000

##sigma = covariance column, we will want to rotate through SDs
##6 = no effect size
##3 = small effect size
##.5 = medium effect size
##.10 = large effect size

##code should cycle through N and SD
##creates fake dataset
##rounds and windsorizes

##run rm anova
##run quade's test

##OMNIBUS - calculate percent p (3 decimals) that fall into .050, .051 - .100, .100 and up
##compare 1 to 2 and 2 to 3, ignore 1 to 3 
##calculate average M diff, CI of M diff, d, CI for d
##p values for each pairwise comparison
##calculate number p value bins

##bayes
##calculate mean difference and HDI of the difference
##calculate number of HDI bins using percent 


####loop should start here####
M = c(2.5, 3.0, 3.5)
mydata = data.table(sim = 1:20000, N = 1:20000, 
                    effect1v2 = 1:20000, effect2v3 = 1:20000, 
                    effect1v3 = 1:20000, stdev = 1:20000,
                    dlow1v2 = 1:20000, dhigh1v2 = 1:20000,
                    dlow1v3 = 1:20000, dhigh1v3 = 1:20000,
                    dlow2v3 = 1:20000, dhigh2v3 = 1:20000,
                    mdiff1v2 = 1:20000, mdiff1v3 = 1:20000,
                    mdiff2v3 = 1:20000, m1 = 1:20000,
                    m2 = 1:20000, m3 = 1:20000,
                    mlow1v2 = 1:20000, mhigh1v2 = 1:20000,
                    mlow1v3 = 1:20000, mhigh1v3 = 1:20000,
                    mlow2v3 = 1:20000, mhigh2v3 = 1:20000,
                    omniP = 1:20000, p1v2 = 1:20000,
                    p2v3 = 1:20000, p1v3 = 1:20000, quadeP = 1:20000,
                    quadeP1v2 = 1:20000, quadeP2v3 = 1:20000,
                    quadeP1v3 = 1:20000, overallBF = 1:20000, BF1v2 = 1:20000,
                    BF1v3 = 1:20000, BF2v3 = 1:20000, oompcc = 1:20000, 
                    oomchance = 1:20000)
round = 0

####sd loop here####
sdplaceholder = c(11.5, 3, .5, .10)
nplaceholder = c(10, 30, 100, 500, 1000)
for (i in 1:length(sdplaceholder)) {
  
  ####n loop here####  
  for (r in 1:length(nplaceholder)) { 
    
    
    ####sims loop here####
    for (q in 1:10) { ##change to 1000 sims when done
      
      ####make the data here####
      sigma = matrix(c(sdplaceholder[i],0,0,0,sdplaceholder[i],0,0,0,sdplaceholder[i]), nrow = 3, ncol = 3)
      
      dataset = as.data.table(rmvnorm(nplaceholder[r], M, sigma))
      dataset = round(dataset, digits = 0)
      dataset[ dataset < 1] = 1
      dataset[ dataset > 7] = 7
      
      ####make sure SDdiff is not zero####
      while (sd(dataset$V1 - dataset$V2) == 0 | 
             sd(dataset$V1 - dataset$V3) == 0 | 
             sd(dataset$V2 - dataset$V3) == 0)
      {
        dataset = as.data.table(rmvnorm(nplaceholder[r], M, sigma))
        dataset = round(dataset, digits = 0)
        dataset[ dataset < 1] = 1
        dataset[ dataset > 7] = 7
        
        if (sd(dataset$V1 - dataset$V2) != 0 &&
            sd(dataset$V1 - dataset$V3) != 0 &&
            sd(dataset$V2 - dataset$V3) != 0) break 
        
      }
      
      ####put in the basic statistics here####
      round = round + 1
      mydata$sim[round] = q
      mydata$N[round] = nplaceholder[r]
      mydata$stdev[round] = sdplaceholder[i]
      mydata$m1[round] = mean(dataset$V1)
      mydata$m2[round] = mean(dataset$V2)
      mydata$m3[round] = mean(dataset$V3)
      
      ####effect size calculations + Mdiff/CI####
      onetotwo = d.deptdiff(mdiff = mean(dataset$V1 - dataset$V2), 
                            sddiff = sd(dataset$V1 - dataset$V2), 
                            n = length(dataset$V1))
      onetothree = d.deptdiff(mdiff = mean(dataset$V1 - dataset$V3), 
                              sddiff = sd(dataset$V1 - dataset$V3), 
                              n = length(dataset$V1))
      twotothree = d.deptdiff(mdiff = mean(dataset$V2 - dataset$V3), 
                              sddiff = sd(dataset$V2 - dataset$V3), 
                              n = length(dataset$V1))
      mydata$effect1v2[round] = onetotwo$d
      mydata$dlow1v2[round] = onetotwo$dlow
      mydata$dhigh1v2[round] = onetotwo$dhigh
      mydata$mdiff1v2[round] = mean(dataset$V1 - dataset$V2)
      mydata$mlow1v2[round] = onetotwo$Mlow
      mydata$mhigh1v2[round] = onetotwo$Mhigh
      
      mydata$effect1v3[round] = onetothree$d
      mydata$dlow1v3[round] = onetothree$dlow
      mydata$dhigh1v3[round] = onetothree$dhigh
      mydata$mdiff1v3[round] = mean(dataset$V1 - dataset$V3)
      mydata$mlow1v3[round] = onetothree$Mlow
      mydata$mhigh1v3[round] = onetothree$Mhigh
      
      mydata$effect2v3[round] = twotothree$d
      mydata$dlow2v3[round] = twotothree$dlow
      mydata$dhigh2v3[round] = twotothree$dhigh
      mydata$mdiff2v3[round] = mean(dataset$V2 - dataset$V3)
      mydata$mlow2v3[round] = twotothree$Mlow
      mydata$mhigh2v3[round] = twotothree$Mhigh
      
      
      ###########################begin RM ANOVA####
      dataset2 = as.data.table(dataset)
      dataset2$partno = as.factor(1:nrow(dataset2))
      longdataset = as.data.table(melt(dataset2,
                                       id = "partno",
                                       measured = c("V1", "V2", "V3")))
      rmoutput = ezANOVA(data = longdataset,
                         wid = partno,
                         within = variable,
                         dv = value,
                         type = 3)
      mydata$omniP[round] = rmoutput$ANOVA$p
      posthocoutput = pairwise.t.test(longdataset$value,
                                      longdataset$variable,
                                      paired = T,
                                      p.adjust.method = "bonferroni")
      mydata$p1v2[round] = posthocoutput$p.value[1,1]
      mydata$p1v3[round] = posthocoutput$p.value[2,1]
      mydata$p2v3[round] = posthocoutput$p.value[2,2]
      ############################End RM ANOVA###
      
      #########################begin Quade####
      Quade = quade.test(value~variable|partno, data = longdataset)
      mydata$quadeP[round] = Quade$p.value
      
      posthocquadeoutput = posthoc.quade.test(longdataset$value,
                                              groups = longdataset$variable,
                                              blocks = longdataset$partno,
                                              p.adjust.method = "bonferroni")
      mydata$quadeP1v2[round] = posthocquadeoutput$p.value[1,1]
      mydata$quadeP1v3[round] = posthocquadeoutput$p.value[2,1]
      mydata$quadeP2v3[round] = posthocquadeoutput$p.value[2,2]
      ###########################end quade###
      
      ########################begin Bayes####
      ##anova uses Jeffries Prior of 1/2 for fixed effects, 1 for nuisance
      BFoutput = anovaBF(value~variable+partno, data = longdataset,
                         whichRandom = "partno",
                         rscaleFixed = 0.5, rscaleRandom = 1,
                         iterations = 1000)
      ##t tests uses a Cauchy Prior of sqrt(2)/2
      BFttest1v2 = ttestBF(x = longdataset$value[longdataset$variable=="V1"],
                           y = longdataset$value[longdataset$variable=="V2"],
                           paired = T, rscale = 0.707, iterations = 1000)
      BFttest1v3 = ttestBF(x = longdataset$value[longdataset$variable=="V1"],
                           y = longdataset$value[longdataset$variable=="V3"],
                           paired = T, rscale = 0.707, iterations = 1000)
      BFttest2v3 = ttestBF(x = longdataset$value[longdataset$variable=="V2"],
                           y = longdataset$value[longdataset$variable=="V3"],
                           paired = T, rscale = 0.707, iterations = 1000)
      mydata$overallBF[round] = unname(as.vector(BFoutput))
      mydata$BF1v2[round] = unname(as.vector(BFttest1v2))
      mydata$BF1v3[round] = unname(as.vector(BFttest1v3))
      mydata$BF2v3[round] = unname(as.vector(BFttest2v3))
      #######################end bayes###
      
      ###########################begin OOM####
      ##1 --> 2 --> 3 ordering
      longdataset$value = as.integer(longdataset$value)
      oom1 = OOM(longdataset$value, longdataset$variable)
      oom1$PCC #percentage correct classification
      oom1c <- OOMc(oom1)
      mydata$oompcc[round] = oom1c$PCCt #PCC
      mydata$oomchance[round] = oom1c$chancevalue #chance value
      ############################end OOM###
      
        } ##sd loop
      
       } ##n loop
      
    } ##sims loop
    
    proc.time() - ptm
    
```
In this study, we generated 20,000 datasets by manipulating sample size and effect size for a repeated measures design with three levels. A repeated measures design was chosen as it is widely used across many disciplines of psychology. These datasets were created using the *mvtnorm* package in *R* [@Genz2017], and all code for simulations can be found at https://osf.io/u9hf4/. Interested readers can easily adapt the *R* code to incorporate different research designs. Likert data, ranging from 1 to 7, was created by rounding *mvtnorm* estimates to whole numbers and truncating any data points out the appropriate range (i.e. values < 1 were rounded to 1, and values > 7 were rounded to 7). We specifically chose Likert-type data as this data type is one of the most common data types utilized by most social scientists. Additionally we add to the literature as other simulations have chosen to use completely continuous data (i.e., simulated numbers are often precise to 10+ decimals, which is unlikely for traditional sampling). The population means for each level were set to 2.5, 3.0, and 3.5, and effect sizes were manipulated by adjusting the standard deviation to create negligible effects (*SD* = 3.39, *d* = 0.10), small effects (*SD* = 3.00, *d* = 0.20), medium effects (*SD* = 0.50, *d* = 0.50), and large effects (*SD* = 0.10, *d* = 0.80) using @Cohen1992a's traditional guidelines for *d* interpretation. The smallest effect size was set such that Likert style data could still be retained with the smallest possible effect size. Sample size was manipulated at 10, 30, 100, 500, and 1,000 data points. All combinations of the five sample sizes and four effect sizes were created, and each dataset was simulated 1,000 times, totaling 20,000 datasets. 
  
The advantage of using *mvtnorm* and set *SDs* for each group was the ability to approximate the assumptions of normality by randomly generating from a multivariate normal distribution, and homogeneity by setting equal *SDs* for each group. In a repeated measures design, the assumption of sphericity was met by setting the correlations between levels in *mvtnorm* to zero. By maintaining the lowest level of relationship between levels, we additionally controlled for power and examined situations of significance given the lowest power scenario. During the data simulation, the standard deviation of the difference scores was examined to maintain differences greater than zero, especially for low *N* simulations. 

## Analyses Performed

### Descriptive Statistics

Means, mean differences between levels, and the confidence intervals for each mean can be found in the complete dataset online, https://osf.io/u9hf4/. For each simulation, we also calculated *d* values using the standard deviation of the difference score as the denominator [$d_{z}$, @Lakens2013]. The *MOTE* library was used to calculate the non-central confidence interval for each *d* value as well [@Cumming2014; @Buchanan2017]. This data was mainly used to determine if simulations were meeting expected values overall. 

### Parametric NHST - Repeated Measures ANOVA

Repeated measures ANOVA using the *ezANOVA()* function in the *ez* library was utilized with type three sum of squares [@Lawrence2017]. This style of ANOVA is used to compare the same individuals across multiple or all conditions in an experiment. The null hypothesis states that there are no significant differences between population means, and the research hypothesis posts that there are differences between population means, but does not specify which population means may differ, just that one or more will differ as the alternative. This test uses the *F* distribution focusing on *p* values. 

To determine where differences may exist, *post hoc* dependent *t*-tests are normally analyzed in the event of a significant *F*-ratio. We did not run all pairwise comparisons, instead focusing on the linear trend simulated by comparing level one to two and level two to three. This set of comparisons also controlled the effect size between comparisons, as comparing level one to three would have doubled the effect size. However, we assumed that the typical researchers might compare all three pairwise combinations in practice and used a Bonferroni correction across all three possible pairwise combinations to calculate *p* values for *post hoc* tests. Therefore, while we only discuss the two comparisons, we utilized the more stringent cutoff of the Bonferroni correction as we believe this procedure would be how the majority of researchers would handle the data. Interested readers can find all three comparison values in the complete dataset online. A *p*-value of less than .05 was binned as significant, whereas *p*-values ranging from .10 to .05 were binned as marginally significant. Any *p*-values larger than .10 were binned as non-significant. A second set of *p*-value comparisons was calculated given @Benjamin2017's suggestion to change $\alpha$ criterion to less than .005. Any *p*-value less than .005 was binned as significant, while data ranging from .005 to .10 was marginal or suggestive, and *p* > .10 was non-significant.

### Bayesian Analysis: Bayes Factor

We compared a null model with one grand mean for all three levels to an effects model wherein means were allowed to differ using the *BayesFactor* package [@Morey2015b]. The default in this package is a Jeffreys prior with a fixed rscale (0.5) and random rscale (1.0). BF were calculated, and follow up *t*-test BFs were computed for the same two comparisons as in the previous models using default priors from the *BayesFactor* package (e.g., Jeffreys prior for population variance, Cauchy prior for standardized effect size). To compare Bayesian results to other statistical methods, we used recommendations from @Kass1995 to bin results into weak evidence (BFs < 3), positive evidence (e.g., akin to marginal *p*-values, BFs = 3-20), and strong evidence (BFs > 20). BF interpretation should focus on understanding the odds of model ratios, and these bins are used here as a convenient comparison to procedures that do have set criteria for interpretation [@Morey2015c].

### OOM: Ordinal Pattern Analysis

An *R* script of the Ordinal Pattern Analysis from @Grice2015's OOM program was provided from @Sauer2016. We set the expected ranked pattern as level one less than level two less than level three. Once this pattern was defined, we then analyzed the data to see if each individual's set of observations matched this expected ordinal pattern. PCC values were generated, and *c*-values were computed by randomizing the data 1,000 times. Solely for purposes of comparison, we used the following significance coding schema: significant studies had a high PCC value (.50 < PCC < 1.00) and a low *c*-value (*c* < .05), marginal studies had a high PCC value and a moderate *c*-value (.05 < *c* < .10), and non-significant studies had low PCC values (PCC < .50), regardless of their *c*-values.

# Results
```{r percent-sig-05, eval=FALSE, include=FALSE}

overall_sims <- read.csv("overall_sims.csv")
data = overall_sims

######################################################################################## Binning
#################################### Bin Omni P NHST
options(scipen=999)
data$BinOmniP = data$omniP
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.05, "significant")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.10, "marginal")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<=1, "non-sig")
data$BinOmniP = factor(data$BinOmniP, levels = c("non-sig","marginal","significant"))
table(data$BinOmniP)
################################# Bin Omni P NHST

################################# Bin 1v2 P NHST
data$Binp1v2 = data$p1v2
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.05, "significant")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.10, "marginal")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<=1, "non-sig")
data$Binp1v2 = factor(data$Binp1v2, levels = c("non-sig","marginal","significant"))
table(data$Binp1v2)
################################ Bin 1v2 P NHST

############################### Bin 1v3 P NHST
data$Binp1v3 = data$p1v3
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.05, "significant")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.10, "marginal")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<=1, "non-sig")
data$Binp1v3 = factor(data$Binp1v3, levels = c("non-sig","marginal","significant"))
table(data$Binp1v3)
############################### Bin 1v3 P NHST

############################# Bin 2v3 P NHST
data$Binp2v3 = data$p2v3
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.05, "significant")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.10, "marginal")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<=1, "non-sig")
data$Binp2v3 = factor(data$Binp2v3, levels = c("non-sig","marginal","significant"))
table(data$Binp2v3)
############################ Bin 2v3 P NHST

############################# Bin omni quades P
data$BinquadeP = data$quadeP
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.05, "significant")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.10, "marginal")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<=1, "non-sig")
data$BinquadeP = factor(data$BinquadeP, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP)
############################ Bin omni quades P

############################# Bin quade P 1v2
data$BinquadeP1v2 = data$quadeP1v2
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.05, "significant")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.10, "marginal")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<=1, "non-sig")
data$BinquadeP1v2 = factor(data$BinquadeP1v2, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v2)
############################ Bin quade P 1v2

############################ Bin quade P 1v3
data$BinquadeP1v3 = data$quadeP1v3
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.05, "significant")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.10, "marginal")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<=1, "non-sig")
data$BinquadeP1v3 = factor(data$BinquadeP1v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v3)
########################### Bin quade P 1v3

############################ Bin quade P 2v3
data$BinquadeP2v3 = data$quadeP2v3
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.05, "significant")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.10, "marginal")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<=1, "non-sig")
data$BinquadeP2v3 = factor(data$BinquadeP2v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP2v3)
########################### Bin quade P 2v3


########################## Bin overall BF
data$BinoverallBF = data$overallBF
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<3, "weak")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<20, "positive")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<=Inf, "strong")
data$BinoverallBF = factor(data$BinoverallBF, levels = c("weak","positive","strong"))
table(data$BinoverallBF)
######################### Bin overall BF

########################## Bin BF 1v2
data$BinBF1v2 = data$BF1v2
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<3, "weak")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<20, "positive")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<=Inf, "strong")
data$BinBF1v2 = factor(data$BinBF1v2, levels = c("weak","positive","strong"))
table(data$BinBF1v2)
######################### Bin BF 1v2

########################## Bin BF 1v3
data$BinBF1v3 = data$BF1v3
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<3, "weak")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<20, "positive")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<=Inf, "strong")
data$BinBF1v3 = factor(data$BinBF1v3, levels = c("weak","positive","strong"))
table(data$BinBF1v3)
######################### Bin BF 1v3

######################### Bin BF 2v3
data$BinBF2v3 = data$BF2v3
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<3, "weak")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<20, "positive")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<=Inf, "strong")
data$BinBF2v3 = factor(data$BinBF2v3, levels = c("weak","positive","strong"))
table(data$BinBF2v3)
######################### Bin BF 2v3

######################### Bin stdev
data$stdev = replace(data$stdev, data$stdev==0.1, "Large")
data$stdev = replace(data$stdev, data$stdev==0.5, "Medium")
data$stdev = replace(data$stdev, data$stdev== 3,  "Small")
data$stdev = replace(data$stdev, data$stdev==11.5, "None")
table(data$stdev)
######################### Bin stdev


########################### Bin oom chance
data$Binoomchance = data$oomchance
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.05, "low")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.10, "medium")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<=1, "high")
data$Binoomchance = factor(data$Binoomchance, levels = c("high","medium","low"))
table(data$Binoomchance)

data$Binoompcc = data$oompcc
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<0.50, "low")
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<1.01, "high")
table(data$Binoompcc)

data$Binoom = 0
round = 0
nsim = nrow(data)

for(i in 1:nsim){
  round = round+1
  if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="low"){
    data$Binoom[round] = "significant"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="medium"){
    data$Binoom[round] = "marginal"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="high"){
    data$Binoom[round] = "non-sig"
  } else if(data$Binoompcc[round]=="low"){
    data$Binoom[round] = "non-sig"
  }
}
data$Binoom = factor(data$Binoom, levels = c("non-sig","marginal","significant"))
table(data$Binoom)
########################### Bin oom chance
######################################################################################## Binning


################################################################################ percent sig ES Large
psig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_Large) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
largedata = subset(data, stdev=="Large")
psig_Large[1,2] = 10
psig_Large[2,2] = 30
psig_Large[3,2] = 100
psig_Large[4,2] = 500
psig_Large[5,2] = 1000
psig_Large[1,1] = "Large"
psig_Large[2,1] = "Large"
psig_Large[3,1] = "Large"
psig_Large[4,1] = "Large"
psig_Large[5,1] = "Large"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinOmniP[largedata$N==place])/
            sum(table(largedata$BinOmniP[largedata$N==place])))*100 
  psig_Large[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp1v2[largedata$N==place])/
            sum(table(largedata$Binp1v2[largedata$N==place])))*100 
  psig_Large[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp1v3[largedata$N==place])/
            sum(table(largedata$Binp1v3[largedata$N==place])))*100 
  psig_Large[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp2v3[largedata$N==place])/
            sum(table(largedata$Binp2v3[largedata$N==place])))*100 
  psig_Large[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP[largedata$N==place])/
            sum(table(largedata$BinquadeP[largedata$N==place])))*100 
  psig_Large[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP1v2[largedata$N==place])/
            sum(table(largedata$BinquadeP1v2[largedata$N==place])))*100 
  psig_Large[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP1v3[largedata$N==place])/
            sum(table(largedata$BinquadeP1v3[largedata$N==place])))*100 
  psig_Large[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP2v3[largedata$N==place])/
            sum(table(largedata$BinquadeP2v3[largedata$N==place])))*100 
  psig_Large[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinoverallBF[largedata$N==place])/
            sum(table(largedata$BinoverallBF[largedata$N==place])))*100 
  psig_Large[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF1v2[largedata$N==place])/
            sum(table(largedata$BinBF1v2[largedata$N==place])))*100 
  psig_Large[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF1v3[largedata$N==place])/
            sum(table(largedata$BinBF1v3[largedata$N==place])))*100 
  psig_Large[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF2v3[largedata$N==place])/
            sum(table(largedata$BinBF2v3[largedata$N==place])))*100 
  psig_Large[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binoom[largedata$N==place])/
            sum(table(largedata$Binoom[largedata$N==place])))*100 
  psig_Large[round,15] = xtab[3]
}
################################################################################ percent sig ES Large


############################################################################### percent sig ES Medium
psig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_Medium) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
mediumdata = subset(data, stdev=="Medium")
psig_Medium[1,2] = 10
psig_Medium[2,2] = 30
psig_Medium[3,2] = 100
psig_Medium[4,2] = 500
psig_Medium[5,2] = 1000
psig_Medium[1,1] = "Medium"
psig_Medium[2,1] = "Medium"
psig_Medium[3,1] = "Medium"
psig_Medium[4,1] = "Medium"
psig_Medium[5,1] = "Medium"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinOmniP[mediumdata$N==place])/
            sum(table(mediumdata$BinOmniP[mediumdata$N==place])))*100 
  psig_Medium[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp1v2[mediumdata$N==place])/
            sum(table(mediumdata$Binp1v2[mediumdata$N==place])))*100 
  psig_Medium[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp1v3[mediumdata$N==place])/
            sum(table(mediumdata$Binp1v3[mediumdata$N==place])))*100 
  psig_Medium[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp2v3[mediumdata$N==place])/
            sum(table(mediumdata$Binp2v3[mediumdata$N==place])))*100 
  psig_Medium[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP[mediumdata$N==place])))*100 
  psig_Medium[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP1v2[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP1v2[mediumdata$N==place])))*100 
  psig_Medium[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP1v3[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP1v3[mediumdata$N==place])))*100 
  psig_Medium[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP2v3[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP2v3[mediumdata$N==place])))*100 
  psig_Medium[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinoverallBF[mediumdata$N==place])/
            sum(table(mediumdata$BinoverallBF[mediumdata$N==place])))*100 
  psig_Medium[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF1v2[mediumdata$N==place])/
            sum(table(mediumdata$BinBF1v2[mediumdata$N==place])))*100 
  psig_Medium[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF1v3[mediumdata$N==place])/
            sum(table(mediumdata$BinBF1v3[mediumdata$N==place])))*100 
  psig_Medium[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF2v3[mediumdata$N==place])/
            sum(table(mediumdata$BinBF2v3[mediumdata$N==place])))*100 
  psig_Medium[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binoom[mediumdata$N==place])/
            sum(table(mediumdata$Binoom[mediumdata$N==place])))*100 
  psig_Medium[round,15] = xtab[3]
}
############################################################################### percent sig ES Medium


############################################################################### percent sig ES Small
psig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_Small) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
smalldata = subset(data, stdev=="Small")
psig_Small[1,2] = 10
psig_Small[2,2] = 30
psig_Small[3,2] = 100
psig_Small[4,2] = 500
psig_Small[5,2] = 1000
psig_Small[1,1] = "Small"
psig_Small[2,1] = "Small"
psig_Small[3,1] = "Small"
psig_Small[4,1] = "Small"
psig_Small[5,1] = "Small"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinOmniP[smalldata$N==place])/
            sum(table(smalldata$BinOmniP[smalldata$N==place])))*100 
  psig_Small[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp1v2[smalldata$N==place])/
            sum(table(smalldata$Binp1v2[smalldata$N==place])))*100 
  psig_Small[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp1v3[smalldata$N==place])/
            sum(table(smalldata$Binp1v3[smalldata$N==place])))*100 
  psig_Small[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp2v3[smalldata$N==place])/
            sum(table(smalldata$Binp2v3[smalldata$N==place])))*100 
  psig_Small[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP[smalldata$N==place])/
            sum(table(smalldata$BinquadeP[smalldata$N==place])))*100 
  psig_Small[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP1v2[smalldata$N==place])/
            sum(table(smalldata$BinquadeP1v2[smalldata$N==place])))*100 
  psig_Small[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP1v3[smalldata$N==place])/
            sum(table(smalldata$BinquadeP1v3[smalldata$N==place])))*100 
  psig_Small[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP2v3[smalldata$N==place])/
            sum(table(smalldata$BinquadeP2v3[smalldata$N==place])))*100 
  psig_Small[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinoverallBF[smalldata$N==place])/
            sum(table(smalldata$BinoverallBF[smalldata$N==place])))*100 
  psig_Small[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF1v2[smalldata$N==place])/
            sum(table(smalldata$BinBF1v2[smalldata$N==place])))*100 
  psig_Small[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF1v3[smalldata$N==place])/
            sum(table(smalldata$BinBF1v3[smalldata$N==place])))*100 
  psig_Small[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF2v3[smalldata$N==place])/
            sum(table(smalldata$BinBF2v3[smalldata$N==place])))*100 
  psig_Small[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binoom[smalldata$N==place])/
            sum(table(smalldata$Binoom[smalldata$N==place])))*100 
  psig_Small[round,15] = xtab[3]
}
############################################################################### percent sig ES Small


############################################################################### percent sig ES None
psig_None = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_None) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
nonedata = subset(data, stdev=="None")
psig_None[1,2] = 10
psig_None[2,2] = 30
psig_None[3,2] = 100
psig_None[4,2] = 500
psig_None[5,2] = 1000
psig_None[1,1] = "None"
psig_None[2,1] = "None"
psig_None[3,1] = "None"
psig_None[4,1] = "None"
psig_None[5,1] = "None"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinOmniP[nonedata$N==place])/
            sum(table(nonedata$BinOmniP[nonedata$N==place])))*100 
  psig_None[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp1v2[nonedata$N==place])/
            sum(table(nonedata$Binp1v2[nonedata$N==place])))*100 
  psig_None[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp1v3[nonedata$N==place])/
            sum(table(nonedata$Binp1v3[nonedata$N==place])))*100 
  psig_None[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp2v3[nonedata$N==place])/
            sum(table(nonedata$Binp2v3[nonedata$N==place])))*100 
  psig_None[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP[nonedata$N==place])/
            sum(table(nonedata$BinquadeP[nonedata$N==place])))*100 
  psig_None[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP1v2[nonedata$N==place])/
            sum(table(nonedata$BinquadeP1v2[nonedata$N==place])))*100 
  psig_None[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP1v3[nonedata$N==place])/
            sum(table(nonedata$BinquadeP1v3[nonedata$N==place])))*100 
  psig_None[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP2v3[nonedata$N==place])/
            sum(table(nonedata$BinquadeP2v3[nonedata$N==place])))*100 
  psig_None[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinoverallBF[nonedata$N==place])/
            sum(table(nonedata$BinoverallBF[nonedata$N==place])))*100 
  psig_None[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF1v2[nonedata$N==place])/
            sum(table(nonedata$BinBF1v2[nonedata$N==place])))*100 
  psig_None[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF1v3[nonedata$N==place])/
            sum(table(nonedata$BinBF1v3[nonedata$N==place])))*100 
  psig_None[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF2v3[nonedata$N==place])/
            sum(table(nonedata$BinBF2v3[nonedata$N==place])))*100 
  psig_None[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binoom[nonedata$N==place])/
            sum(table(nonedata$Binoom[nonedata$N==place])))*100 
  psig_None[round,15] = xtab[3]
}
############################################################################### percent sig ES None


###################### View percent significant datasets
View(psig_Large)
View(psig_Medium)
View(psig_Small)
View(psig_None)

percentsig = rbind(psig_Large,psig_Medium,
                   psig_Small,psig_None)
View(percentsig)
write.csv(percentsig, file = "PercentSig.05.csv")
###################### View percent significant datasets

```

```{r percent-sig-005, eval=FALSE, include=FALSE}

overall_sims <- read.csv("overall_sims.csv")
data = overall_sims

######################################################################################## Binning
#################################### Bin Omni P NHST
options(scipen=999)
data$BinOmniP = data$omniP
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.005, "significant")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.10, "marginal")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<=1, "non-sig")
data$BinOmniP = factor(data$BinOmniP, levels = c("non-sig","marginal","significant"))
table(data$BinOmniP)
################################# Bin Omni P NHST

################################# Bin 1v2 P NHST
data$Binp1v2 = data$p1v2
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.005, "significant")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.10, "marginal")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<=1, "non-sig")
data$Binp1v2 = factor(data$Binp1v2, levels = c("non-sig","marginal","significant"))
table(data$Binp1v2)
################################ Bin 1v2 P NHST

############################### Bin 1v3 P NHST
data$Binp1v3 = data$p1v3
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.005, "significant")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.10, "marginal")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<=1, "non-sig")
data$Binp1v3 = factor(data$Binp1v3, levels = c("non-sig","marginal","significant"))
table(data$Binp1v3)
############################### Bin 1v3 P NHST

############################# Bin 2v3 P NHST
data$Binp2v3 = data$p2v3
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.005, "significant")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.10, "marginal")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<=1, "non-sig")
data$Binp2v3 = factor(data$Binp2v3, levels = c("non-sig","marginal","significant"))
table(data$Binp2v3)
############################ Bin 2v3 P NHST

############################# Bin omni quades P
data$BinquadeP = data$quadeP
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.005, "significant")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.10, "marginal")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<=1, "non-sig")
data$BinquadeP = factor(data$BinquadeP, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP)
############################ Bin omni quades P

############################# Bin quade P 1v2
data$BinquadeP1v2 = data$quadeP1v2
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.005, "significant")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.10, "marginal")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<=1, "non-sig")
data$BinquadeP1v2 = factor(data$BinquadeP1v2, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v2)
############################ Bin quade P 1v2

############################ Bin quade P 1v3
data$BinquadeP1v3 = data$quadeP1v3
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.005, "significant")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.10, "marginal")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<=1, "non-sig")
data$BinquadeP1v3 = factor(data$BinquadeP1v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v3)
########################### Bin quade P 1v3

############################ Bin quade P 2v3
data$BinquadeP2v3 = data$quadeP2v3
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.005, "significant")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.10, "marginal")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<=1, "non-sig")
data$BinquadeP2v3 = factor(data$BinquadeP2v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP2v3)
########################### Bin quade P 2v3


########################## Bin overall BF
data$BinoverallBF = data$overallBF
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<3, "weak")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<20, "positive")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<=Inf, "strong")
data$BinoverallBF = factor(data$BinoverallBF, levels = c("weak","positive","strong"))
table(data$BinoverallBF)
######################### Bin overall BF

########################## Bin BF 1v2
data$BinBF1v2 = data$BF1v2
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<3, "weak")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<20, "positive")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<=Inf, "strong")
data$BinBF1v2 = factor(data$BinBF1v2, levels = c("weak","positive","strong"))
table(data$BinBF1v2)
######################### Bin BF 1v2

########################## Bin BF 1v3
data$BinBF1v3 = data$BF1v3
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<3, "weak")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<20, "positive")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<=Inf, "strong")
data$BinBF1v3 = factor(data$BinBF1v3, levels = c("weak","positive","strong"))
table(data$BinBF1v3)
######################### Bin BF 1v3

######################### Bin BF 2v3
data$BinBF2v3 = data$BF2v3
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<3, "weak")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<20, "positive")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<=Inf, "strong")
data$BinBF2v3 = factor(data$BinBF2v3, levels = c("weak","positive","strong"))
table(data$BinBF2v3)
######################### Bin BF 2v3

######################### Bin stdev
data$stdev = replace(data$stdev, data$stdev==0.1, "Large")
data$stdev = replace(data$stdev, data$stdev==0.5, "Medium")
data$stdev = replace(data$stdev, data$stdev== 3,  "Small")
data$stdev = replace(data$stdev, data$stdev==11.5, "None")
table(data$stdev)
######################### Bin stdev


########################### Bin oom chance
data$Binoomchance = data$oomchance
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.05, "low")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.10, "medium")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<=1, "high")
data$Binoomchance = factor(data$Binoomchance, levels = c("high","medium","low"))
table(data$Binoomchance)

data$Binoompcc = data$oompcc
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<0.50, "low")
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<1.01, "high")
table(data$Binoompcc)

data$Binoom = 0
round = 0
nsim = nrow(data)

for(i in 1:nsim){
  round = round+1
  if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="low"){
    data$Binoom[round] = "significant"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="medium"){
    data$Binoom[round] = "marginal"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="high"){
    data$Binoom[round] = "non-sig"
  } else if(data$Binoompcc[round]=="low"){
    data$Binoom[round] = "non-sig"
  }
}
data$Binoom = factor(data$Binoom, levels = c("non-sig","marginal","significant"))
table(data$Binoom)
########################### Bin oom chance
######################################################################################## Binning


################################################################################ percent sig ES Large
psig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_Large) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
largedata = subset(data, stdev=="Large")
psig_Large[1,2] = 10
psig_Large[2,2] = 30
psig_Large[3,2] = 100
psig_Large[4,2] = 500
psig_Large[5,2] = 1000
psig_Large[1,1] = "Large"
psig_Large[2,1] = "Large"
psig_Large[3,1] = "Large"
psig_Large[4,1] = "Large"
psig_Large[5,1] = "Large"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinOmniP[largedata$N==place])/
            sum(table(largedata$BinOmniP[largedata$N==place])))*100 
  psig_Large[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp1v2[largedata$N==place])/
            sum(table(largedata$Binp1v2[largedata$N==place])))*100 
  psig_Large[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp1v3[largedata$N==place])/
            sum(table(largedata$Binp1v3[largedata$N==place])))*100 
  psig_Large[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp2v3[largedata$N==place])/
            sum(table(largedata$Binp2v3[largedata$N==place])))*100 
  psig_Large[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP[largedata$N==place])/
            sum(table(largedata$BinquadeP[largedata$N==place])))*100 
  psig_Large[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP1v2[largedata$N==place])/
            sum(table(largedata$BinquadeP1v2[largedata$N==place])))*100 
  psig_Large[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP1v3[largedata$N==place])/
            sum(table(largedata$BinquadeP1v3[largedata$N==place])))*100 
  psig_Large[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP2v3[largedata$N==place])/
            sum(table(largedata$BinquadeP2v3[largedata$N==place])))*100 
  psig_Large[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinoverallBF[largedata$N==place])/
            sum(table(largedata$BinoverallBF[largedata$N==place])))*100 
  psig_Large[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF1v2[largedata$N==place])/
            sum(table(largedata$BinBF1v2[largedata$N==place])))*100 
  psig_Large[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF1v3[largedata$N==place])/
            sum(table(largedata$BinBF1v3[largedata$N==place])))*100 
  psig_Large[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF2v3[largedata$N==place])/
            sum(table(largedata$BinBF2v3[largedata$N==place])))*100 
  psig_Large[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binoom[largedata$N==place])/
            sum(table(largedata$Binoom[largedata$N==place])))*100 
  psig_Large[round,15] = xtab[3]
}
################################################################################ percent sig ES Large


############################################################################### percent sig ES Medium
psig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_Medium) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                       "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                       "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                       "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
mediumdata = subset(data, stdev=="Medium")
psig_Medium[1,2] = 10
psig_Medium[2,2] = 30
psig_Medium[3,2] = 100
psig_Medium[4,2] = 500
psig_Medium[5,2] = 1000
psig_Medium[1,1] = "Medium"
psig_Medium[2,1] = "Medium"
psig_Medium[3,1] = "Medium"
psig_Medium[4,1] = "Medium"
psig_Medium[5,1] = "Medium"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinOmniP[mediumdata$N==place])/
            sum(table(mediumdata$BinOmniP[mediumdata$N==place])))*100 
  psig_Medium[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp1v2[mediumdata$N==place])/
            sum(table(mediumdata$Binp1v2[mediumdata$N==place])))*100 
  psig_Medium[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp1v3[mediumdata$N==place])/
            sum(table(mediumdata$Binp1v3[mediumdata$N==place])))*100 
  psig_Medium[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp2v3[mediumdata$N==place])/
            sum(table(mediumdata$Binp2v3[mediumdata$N==place])))*100 
  psig_Medium[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP[mediumdata$N==place])))*100 
  psig_Medium[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP1v2[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP1v2[mediumdata$N==place])))*100 
  psig_Medium[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP1v3[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP1v3[mediumdata$N==place])))*100 
  psig_Medium[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP2v3[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP2v3[mediumdata$N==place])))*100 
  psig_Medium[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinoverallBF[mediumdata$N==place])/
            sum(table(mediumdata$BinoverallBF[mediumdata$N==place])))*100 
  psig_Medium[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF1v2[mediumdata$N==place])/
            sum(table(mediumdata$BinBF1v2[mediumdata$N==place])))*100 
  psig_Medium[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF1v3[mediumdata$N==place])/
            sum(table(mediumdata$BinBF1v3[mediumdata$N==place])))*100 
  psig_Medium[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF2v3[mediumdata$N==place])/
            sum(table(mediumdata$BinBF2v3[mediumdata$N==place])))*100 
  psig_Medium[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binoom[mediumdata$N==place])/
            sum(table(mediumdata$Binoom[mediumdata$N==place])))*100 
  psig_Medium[round,15] = xtab[3]
}
############################################################################### percent sig ES Medium


############################################################################### percent sig ES Small
psig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_Small) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
smalldata = subset(data, stdev=="Small")
psig_Small[1,2] = 10
psig_Small[2,2] = 30
psig_Small[3,2] = 100
psig_Small[4,2] = 500
psig_Small[5,2] = 1000
psig_Small[1,1] = "Small"
psig_Small[2,1] = "Small"
psig_Small[3,1] = "Small"
psig_Small[4,1] = "Small"
psig_Small[5,1] = "Small"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinOmniP[smalldata$N==place])/
            sum(table(smalldata$BinOmniP[smalldata$N==place])))*100 
  psig_Small[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp1v2[smalldata$N==place])/
            sum(table(smalldata$Binp1v2[smalldata$N==place])))*100 
  psig_Small[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp1v3[smalldata$N==place])/
            sum(table(smalldata$Binp1v3[smalldata$N==place])))*100 
  psig_Small[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp2v3[smalldata$N==place])/
            sum(table(smalldata$Binp2v3[smalldata$N==place])))*100 
  psig_Small[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP[smalldata$N==place])/
            sum(table(smalldata$BinquadeP[smalldata$N==place])))*100 
  psig_Small[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP1v2[smalldata$N==place])/
            sum(table(smalldata$BinquadeP1v2[smalldata$N==place])))*100 
  psig_Small[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP1v3[smalldata$N==place])/
            sum(table(smalldata$BinquadeP1v3[smalldata$N==place])))*100 
  psig_Small[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP2v3[smalldata$N==place])/
            sum(table(smalldata$BinquadeP2v3[smalldata$N==place])))*100 
  psig_Small[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinoverallBF[smalldata$N==place])/
            sum(table(smalldata$BinoverallBF[smalldata$N==place])))*100 
  psig_Small[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF1v2[smalldata$N==place])/
            sum(table(smalldata$BinBF1v2[smalldata$N==place])))*100 
  psig_Small[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF1v3[smalldata$N==place])/
            sum(table(smalldata$BinBF1v3[smalldata$N==place])))*100 
  psig_Small[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF2v3[smalldata$N==place])/
            sum(table(smalldata$BinBF2v3[smalldata$N==place])))*100 
  psig_Small[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binoom[smalldata$N==place])/
            sum(table(smalldata$Binoom[smalldata$N==place])))*100 
  psig_Small[round,15] = xtab[3]
}
############################################################################### percent sig ES Small


############################################################################### percent sig ES None
psig_None = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(psig_None) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                     "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                     "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                     "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
nonedata = subset(data, stdev=="None")
psig_None[1,2] = 10
psig_None[2,2] = 30
psig_None[3,2] = 100
psig_None[4,2] = 500
psig_None[5,2] = 1000
psig_None[1,1] = "None"
psig_None[2,1] = "None"
psig_None[3,1] = "None"
psig_None[4,1] = "None"
psig_None[5,1] = "None"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinOmniP[nonedata$N==place])/
            sum(table(nonedata$BinOmniP[nonedata$N==place])))*100 
  psig_None[round,3] = xtab[3]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp1v2[nonedata$N==place])/
            sum(table(nonedata$Binp1v2[nonedata$N==place])))*100 
  psig_None[round,4] = xtab[3]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp1v3[nonedata$N==place])/
            sum(table(nonedata$Binp1v3[nonedata$N==place])))*100 
  psig_None[round,5] = xtab[3]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp2v3[nonedata$N==place])/
            sum(table(nonedata$Binp2v3[nonedata$N==place])))*100 
  psig_None[round,6] = xtab[3]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP[nonedata$N==place])/
            sum(table(nonedata$BinquadeP[nonedata$N==place])))*100 
  psig_None[round,7] = xtab[3]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP1v2[nonedata$N==place])/
            sum(table(nonedata$BinquadeP1v2[nonedata$N==place])))*100 
  psig_None[round,8] = xtab[3]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP1v3[nonedata$N==place])/
            sum(table(nonedata$BinquadeP1v3[nonedata$N==place])))*100 
  psig_None[round,9] = xtab[3]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP2v3[nonedata$N==place])/
            sum(table(nonedata$BinquadeP2v3[nonedata$N==place])))*100 
  psig_None[round,10] = xtab[3]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinoverallBF[nonedata$N==place])/
            sum(table(nonedata$BinoverallBF[nonedata$N==place])))*100 
  psig_None[round,11] = xtab[3]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF1v2[nonedata$N==place])/
            sum(table(nonedata$BinBF1v2[nonedata$N==place])))*100 
  psig_None[round,12] = xtab[3]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF1v3[nonedata$N==place])/
            sum(table(nonedata$BinBF1v3[nonedata$N==place])))*100 
  psig_None[round,13] = xtab[3]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF2v3[nonedata$N==place])/
            sum(table(nonedata$BinBF2v3[nonedata$N==place])))*100 
  psig_None[round,14] = xtab[3]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binoom[nonedata$N==place])/
            sum(table(nonedata$Binoom[nonedata$N==place])))*100 
  psig_None[round,15] = xtab[3]
}
############################################################################### percent sig ES None


###################### View percent significant datasets
View(psig_Large)
View(psig_Medium)
View(psig_Small)
View(psig_None)

percentsig = rbind(psig_Large,psig_Medium,
                   psig_Small,psig_None)
View(percentsig)
write.csv(percentsig, file = "PercentSig.005.csv")
###################### View percent significant datasets
```

```{r percent-nsig, eval=FALSE, include=FALSE}

overall_sims <- read.csv("overall_sims.csv")
data = overall_sims

######################################################################################## Binning
#################################### Bin Omni P NHST
options(scipen=999)
data$BinOmniP = data$omniP
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.05, "significant")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.10, "marginal")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<=1, "non-sig")
data$BinOmniP = factor(data$BinOmniP, levels = c("non-sig","marginal","significant"))
table(data$BinOmniP)
################################# Bin Omni P NHST

################################# Bin 1v2 P NHST
data$Binp1v2 = data$p1v2
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.05, "significant")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.10, "marginal")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<=1, "non-sig")
data$Binp1v2 = factor(data$Binp1v2, levels = c("non-sig","marginal","significant"))
table(data$Binp1v2)
################################ Bin 1v2 P NHST

############################### Bin 1v3 P NHST
data$Binp1v3 = data$p1v3
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.05, "significant")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.10, "marginal")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<=1, "non-sig")
data$Binp1v3 = factor(data$Binp1v3, levels = c("non-sig","marginal","significant"))
table(data$Binp1v3)
############################### Bin 1v3 P NHST

############################# Bin 2v3 P NHST
data$Binp2v3 = data$p2v3
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.05, "significant")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.10, "marginal")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<=1, "non-sig")
data$Binp2v3 = factor(data$Binp2v3, levels = c("non-sig","marginal","significant"))
table(data$Binp2v3)
############################ Bin 2v3 P NHST

############################# Bin omni quades P
data$BinquadeP = data$quadeP
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.05, "significant")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.10, "marginal")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<=1, "non-sig")
data$BinquadeP = factor(data$BinquadeP, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP)
############################ Bin omni quades P

############################# Bin quade P 1v2
data$BinquadeP1v2 = data$quadeP1v2
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.05, "significant")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.10, "marginal")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<=1, "non-sig")
data$BinquadeP1v2 = factor(data$BinquadeP1v2, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v2)
############################ Bin quade P 1v2

############################ Bin quade P 1v3
data$BinquadeP1v3 = data$quadeP1v3
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.05, "significant")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.10, "marginal")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<=1, "non-sig")
data$BinquadeP1v3 = factor(data$BinquadeP1v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v3)
########################### Bin quade P 1v3

############################ Bin quade P 2v3
data$BinquadeP2v3 = data$quadeP2v3
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.05, "significant")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.10, "marginal")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<=1, "non-sig")
data$BinquadeP2v3 = factor(data$BinquadeP2v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP2v3)
########################### Bin quade P 2v3


########################## Bin overall BF
data$BinoverallBF = data$overallBF
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<3, "weak")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<20, "positive")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<=Inf, "strong")
data$BinoverallBF = factor(data$BinoverallBF, levels = c("weak","positive","strong"))
table(data$BinoverallBF)
######################### Bin overall BF

########################## Bin BF 1v2
data$BinBF1v2 = data$BF1v2
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<3, "weak")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<20, "positive")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<=Inf, "strong")
data$BinBF1v2 = factor(data$BinBF1v2, levels = c("weak","positive","strong"))
table(data$BinBF1v2)
######################### Bin BF 1v2

########################## Bin BF 1v3
data$BinBF1v3 = data$BF1v3
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<3, "weak")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<20, "positive")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<=Inf, "strong")
data$BinBF1v3 = factor(data$BinBF1v3, levels = c("weak","positive","strong"))
table(data$BinBF1v3)
######################### Bin BF 1v3

######################### Bin BF 2v3
data$BinBF2v3 = data$BF2v3
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<3, "weak")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<20, "positive")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<=Inf, "strong")
data$BinBF2v3 = factor(data$BinBF2v3, levels = c("weak","positive","strong"))
table(data$BinBF2v3)
######################### Bin BF 2v3

######################### Bin stdev
data$stdev = replace(data$stdev, data$stdev==0.1, "Large")
data$stdev = replace(data$stdev, data$stdev==0.5, "Medium")
data$stdev = replace(data$stdev, data$stdev== 3,  "Small")
data$stdev = replace(data$stdev, data$stdev==11.5, "None")
table(data$stdev)
######################### Bin stdev


########################### Bin oom chance
data$Binoomchance = data$oomchance
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.05, "low")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.10, "medium")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<=1, "high")
data$Binoomchance = factor(data$Binoomchance, levels = c("high","medium","low"))
table(data$Binoomchance)

data$Binoompcc = data$oompcc
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<0.50, "low")
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<1.01, "high")
table(data$Binoompcc)

data$Binoom = 0
round = 0
nsim = nrow(data)

for(i in 1:nsim){
  round = round+1
  if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="low"){
    data$Binoom[round] = "significant"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="medium"){
    data$Binoom[round] = "marginal"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="high"){
    data$Binoom[round] = "non-sig"
  } else if(data$Binoompcc[round]=="low"){
    data$Binoom[round] = "non-sig"
  }
}
data$Binoom = factor(data$Binoom, levels = c("non-sig","marginal","significant"))
table(data$Binoom)
########################### Bin oom chance
######################################################################################## Binning


################################################################################ percent non sig ES Large
pnonsig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(pnonsig_Large) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
largedata = subset(data, stdev=="Large")
pnonsig_Large[1,2] = 10
pnonsig_Large[2,2] = 30
pnonsig_Large[3,2] = 100
pnonsig_Large[4,2] = 500
pnonsig_Large[5,2] = 1000
pnonsig_Large[1,1] = "Large"
pnonsig_Large[2,1] = "Large"
pnonsig_Large[3,1] = "Large"
pnonsig_Large[4,1] = "Large"
pnonsig_Large[5,1] = "Large"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinOmniP[largedata$N==place])/
            sum(table(largedata$BinOmniP[largedata$N==place])))*100 
  pnonsig_Large[round,3] = xtab[1]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp1v2[largedata$N==place])/
            sum(table(largedata$Binp1v2[largedata$N==place])))*100 
  pnonsig_Large[round,4] = xtab[1]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp1v3[largedata$N==place])/
            sum(table(largedata$Binp1v3[largedata$N==place])))*100 
  pnonsig_Large[round,5] = xtab[1]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binp2v3[largedata$N==place])/
            sum(table(largedata$Binp2v3[largedata$N==place])))*100 
  pnonsig_Large[round,6] = xtab[1]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP[largedata$N==place])/
            sum(table(largedata$BinquadeP[largedata$N==place])))*100 
  pnonsig_Large[round,7] = xtab[1]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP1v2[largedata$N==place])/
            sum(table(largedata$BinquadeP1v2[largedata$N==place])))*100 
  pnonsig_Large[round,8] = xtab[1]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP1v3[largedata$N==place])/
            sum(table(largedata$BinquadeP1v3[largedata$N==place])))*100 
  pnonsig_Large[round,9] = xtab[1]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinquadeP2v3[largedata$N==place])/
            sum(table(largedata$BinquadeP2v3[largedata$N==place])))*100 
  pnonsig_Large[round,10] = xtab[1]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinoverallBF[largedata$N==place])/
            sum(table(largedata$BinoverallBF[largedata$N==place])))*100 
  pnonsig_Large[round,11] = xtab[1]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF1v2[largedata$N==place])/
            sum(table(largedata$BinBF1v2[largedata$N==place])))*100 
  pnonsig_Large[round,12] = xtab[1]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF1v3[largedata$N==place])/
            sum(table(largedata$BinBF1v3[largedata$N==place])))*100 
  pnonsig_Large[round,13] = xtab[1]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$BinBF2v3[largedata$N==place])/
            sum(table(largedata$BinBF2v3[largedata$N==place])))*100 
  pnonsig_Large[round,14] = xtab[1]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(largedata$Binoom[largedata$N==place])/
            sum(table(largedata$Binoom[largedata$N==place])))*100 
  pnonsig_Large[round,15] = xtab[1]
}
################################################################################ percent non sig ES Large


############################################################################### percent non sig ES Medium
pnonsig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(pnonsig_Medium) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                       "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                       "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                       "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
mediumdata = subset(data, stdev=="Medium")
pnonsig_Medium[1,2] = 10
pnonsig_Medium[2,2] = 30
pnonsig_Medium[3,2] = 100
pnonsig_Medium[4,2] = 500
pnonsig_Medium[5,2] = 1000
pnonsig_Medium[1,1] = "Medium"
pnonsig_Medium[2,1] = "Medium"
pnonsig_Medium[3,1] = "Medium"
pnonsig_Medium[4,1] = "Medium"
pnonsig_Medium[5,1] = "Medium"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinOmniP[mediumdata$N==place])/
            sum(table(mediumdata$BinOmniP[mediumdata$N==place])))*100 
  pnonsig_Medium[round,3] = xtab[1]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp1v2[mediumdata$N==place])/
            sum(table(mediumdata$Binp1v2[mediumdata$N==place])))*100 
  pnonsig_Medium[round,4] = xtab[1]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp1v3[mediumdata$N==place])/
            sum(table(mediumdata$Binp1v3[mediumdata$N==place])))*100 
  pnonsig_Medium[round,5] = xtab[1]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binp2v3[mediumdata$N==place])/
            sum(table(mediumdata$Binp2v3[mediumdata$N==place])))*100 
  pnonsig_Medium[round,6] = xtab[1]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP[mediumdata$N==place])))*100 
  pnonsig_Medium[round,7] = xtab[1]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP1v2[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP1v2[mediumdata$N==place])))*100 
  pnonsig_Medium[round,8] = xtab[1]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP1v3[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP1v3[mediumdata$N==place])))*100 
  pnonsig_Medium[round,9] = xtab[1]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinquadeP2v3[mediumdata$N==place])/
            sum(table(mediumdata$BinquadeP2v3[mediumdata$N==place])))*100 
  pnonsig_Medium[round,10] = xtab[1]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinoverallBF[mediumdata$N==place])/
            sum(table(mediumdata$BinoverallBF[mediumdata$N==place])))*100 
  pnonsig_Medium[round,11] = xtab[1]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF1v2[mediumdata$N==place])/
            sum(table(mediumdata$BinBF1v2[mediumdata$N==place])))*100 
  pnonsig_Medium[round,12] = xtab[1]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF1v3[mediumdata$N==place])/
            sum(table(mediumdata$BinBF1v3[mediumdata$N==place])))*100 
  pnonsig_Medium[round,13] = xtab[1]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$BinBF2v3[mediumdata$N==place])/
            sum(table(mediumdata$BinBF2v3[mediumdata$N==place])))*100 
  pnonsig_Medium[round,14] = xtab[1]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(mediumdata$Binoom[mediumdata$N==place])/
            sum(table(mediumdata$Binoom[mediumdata$N==place])))*100 
  pnonsig_Medium[round,15] = xtab[1]
}
############################################################################### percent non sig ES Medium


############################################################################### percent non sig ES Small
pnonsig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(pnonsig_Small) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                      "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                      "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                      "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
smalldata = subset(data, stdev=="Small")
pnonsig_Small[1,2] = 10
pnonsig_Small[2,2] = 30
pnonsig_Small[3,2] = 100
pnonsig_Small[4,2] = 500
pnonsig_Small[5,2] = 1000
pnonsig_Small[1,1] = "Small"
pnonsig_Small[2,1] = "Small"
pnonsig_Small[3,1] = "Small"
pnonsig_Small[4,1] = "Small"
pnonsig_Small[5,1] = "Small"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinOmniP[smalldata$N==place])/
            sum(table(smalldata$BinOmniP[smalldata$N==place])))*100 
  pnonsig_Small[round,3] = xtab[1]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp1v2[smalldata$N==place])/
            sum(table(smalldata$Binp1v2[smalldata$N==place])))*100 
  pnonsig_Small[round,4] = xtab[1]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp1v3[smalldata$N==place])/
            sum(table(smalldata$Binp1v3[smalldata$N==place])))*100 
  pnonsig_Small[round,5] = xtab[1]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binp2v3[smalldata$N==place])/
            sum(table(smalldata$Binp2v3[smalldata$N==place])))*100 
  pnonsig_Small[round,6] = xtab[1]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP[smalldata$N==place])/
            sum(table(smalldata$BinquadeP[smalldata$N==place])))*100 
  pnonsig_Small[round,7] = xtab[1]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP1v2[smalldata$N==place])/
            sum(table(smalldata$BinquadeP1v2[smalldata$N==place])))*100 
  pnonsig_Small[round,8] = xtab[1]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP1v3[smalldata$N==place])/
            sum(table(smalldata$BinquadeP1v3[smalldata$N==place])))*100 
  pnonsig_Small[round,9] = xtab[1]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinquadeP2v3[smalldata$N==place])/
            sum(table(smalldata$BinquadeP2v3[smalldata$N==place])))*100 
  pnonsig_Small[round,10] = xtab[1]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinoverallBF[smalldata$N==place])/
            sum(table(smalldata$BinoverallBF[smalldata$N==place])))*100 
  pnonsig_Small[round,11] = xtab[1]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF1v2[smalldata$N==place])/
            sum(table(smalldata$BinBF1v2[smalldata$N==place])))*100 
  pnonsig_Small[round,12] = xtab[1]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF1v3[smalldata$N==place])/
            sum(table(smalldata$BinBF1v3[smalldata$N==place])))*100 
  pnonsig_Small[round,13] = xtab[1]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$BinBF2v3[smalldata$N==place])/
            sum(table(smalldata$BinBF2v3[smalldata$N==place])))*100 
  pnonsig_Small[round,14] = xtab[1]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(smalldata$Binoom[smalldata$N==place])/
            sum(table(smalldata$Binoom[smalldata$N==place])))*100 
  pnonsig_Small[round,15] = xtab[1]
}
############################################################################### percent non sig ES Small


############################################################################### percent non sig ES None
pnonsig_None = as.data.frame(matrix(0, nrow = 5, ncol = 15))
names(pnonsig_None) = c("Effect", "N","Parametric NHST Omnibus", "Parametric NHST 1v2", "Parametric NHST 1v3",
                     "Parametric NHST 2v3", "Non-Parametric NHST Omnibus", "Non-Parametric 1v2",
                     "Non-Parametric NHST 1v3", "Non-Parametric 2v3", "Bayes Factor Omnibus",
                     "Bayes Factor 1v2", "Bayes Factor 1v3", "Bayes Factor 2v3", "Observation Oriented Model")
nonedata = subset(data, stdev=="None")
pnonsig_None[1,2] = 10
pnonsig_None[2,2] = 30
pnonsig_None[3,2] = 100
pnonsig_None[4,2] = 500
pnonsig_None[5,2] = 1000
pnonsig_None[1,1] = "None"
pnonsig_None[2,1] = "None"
pnonsig_None[3,1] = "None"
pnonsig_None[4,1] = "None"
pnonsig_None[5,1] = "None"

#Parametric NHST omnibus
nplaceholder = c(10, 30, 100, 500, 1000)
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinOmniP[nonedata$N==place])/
            sum(table(nonedata$BinOmniP[nonedata$N==place])))*100 
  pnonsig_None[round,3] = xtab[1]
}

#Parametric NHST 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp1v2[nonedata$N==place])/
            sum(table(nonedata$Binp1v2[nonedata$N==place])))*100 
  pnonsig_None[round,4] = xtab[1]
}

#Parametric NHST 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp1v3[nonedata$N==place])/
            sum(table(nonedata$Binp1v3[nonedata$N==place])))*100 
  pnonsig_None[round,5] = xtab[1]
}

#Parametric NHST 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binp2v3[nonedata$N==place])/
            sum(table(nonedata$Binp2v3[nonedata$N==place])))*100 
  pnonsig_None[round,6] = xtab[1]
}

#Non-Parametric Quade's Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP[nonedata$N==place])/
            sum(table(nonedata$BinquadeP[nonedata$N==place])))*100 
  pnonsig_None[round,7] = xtab[1]
}

#Non-Parametric Quade's 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP1v2[nonedata$N==place])/
            sum(table(nonedata$BinquadeP1v2[nonedata$N==place])))*100 
  pnonsig_None[round,8] = xtab[1]
}

#Non-Parametric Quade's 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP1v3[nonedata$N==place])/
            sum(table(nonedata$BinquadeP1v3[nonedata$N==place])))*100 
  pnonsig_None[round,9] = xtab[1]
}

#Non-Parametric Quade's 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinquadeP2v3[nonedata$N==place])/
            sum(table(nonedata$BinquadeP2v3[nonedata$N==place])))*100 
  pnonsig_None[round,10] = xtab[1]
}

#Bayes Factor Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinoverallBF[nonedata$N==place])/
            sum(table(nonedata$BinoverallBF[nonedata$N==place])))*100 
  pnonsig_None[round,11] = xtab[1]
}

#Bayes Factor 1v2
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF1v2[nonedata$N==place])/
            sum(table(nonedata$BinBF1v2[nonedata$N==place])))*100 
  pnonsig_None[round,12] = xtab[1]
}

#Bayes Factor 1v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF1v3[nonedata$N==place])/
            sum(table(nonedata$BinBF1v3[nonedata$N==place])))*100 
  pnonsig_None[round,13] = xtab[1]
}

#Bayes Factor 2v3
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$BinBF2v3[nonedata$N==place])/
            sum(table(nonedata$BinBF2v3[nonedata$N==place])))*100 
  pnonsig_None[round,14] = xtab[1]
}

#OOM Omnibus
round=0
for(i in 1:length(nplaceholder)){
  round=round+1
  place = nplaceholder[i]
  xtab = (table(nonedata$Binoom[nonedata$N==place])/
            sum(table(nonedata$Binoom[nonedata$N==place])))*100 
  pnonsig_None[round,15] = xtab[1]
}
############################################################################### percent non sig ES None


###################### View percent non significant datasets
View(pnonsig_Large)
View(pnonsig_Medium)
View(pnonsig_Small)
View(pnonsig_None)

percentnonsig = rbind(pnonsig_Large,pnonsig_Medium,
                   pnonsig_Small,pnonsig_None)
View(percentnonsig)
write.csv(percentnonsig, file = "PercentNonSig.csv")
###################### View percent non significant datasets
```

## Percent of Estimates

For all simulations, we first binned the estimates into significant, marginal, and non-significant effect categories as described in the Analyses Performed section above. Next, we calculated the percentage of these analyses that would be classified into each of these categories, separated about by statistical analysis, sample size, and effect size. These estimates were binned across both the overall and follow up *post hoc* tests, and the combined data is presented for this analysis. Since all three categories of binning total to 100%, we present only the significant and non-significant results. All analyses and findings can be found online at https://osf.io/u9hf4/. Significant critical omnibus estimates are presented in Figure \@ref(fig:effects-graph-sig). All figures discussed in this manuscript may be viewed as interactive graphics on our OSF page through a provided Shiny app. In Figures with sample size on the axes, we log transformed *N* to allow for visual distinction between sample sizes, as smaller *N* values were compressed when using the *N* = 10 to 1000 on the axis. Both *N* and log(*N*) can be found in the Shiny app, along with the ability to zoom in to specific ranges of sample size.

For negligible effects at $p$ < .05 (solid lines), we found that NSHT analyses showed a predictable Type I error bias, in that they detected significant estimates with extremely small *d* values as sample size increased. Binned BF values showed a similar pattern, but were more conservative with less percent significant estimates. OOM analyses were the most conservative, essentially never detecting an estimate in the negligible effect simulations. Small effect sizes showed the same pattern for NHST, BF, and OOM results, with the proportion of significant estimates increasing more rapidly and asymptoting at a smaller sample size than negligible effects. At medium effect sizes, NHST analyses nearly always detected significant estimates, while BF and OOM analyses would have been considered significant around 75% of the time. Interestingly, with large effect sizes, OOM analyses mirrored NHST by always detecting estimates, and BF analyses were generally more conservative except at the largest sample size. Figure \@ref(fig:effects-graph-sig)'s dashed lines indicate the results if values were binned at *p* < .005, and the differences between these results were very subtle. Lowering $\alpha$ reduced the number of significant estimates at small *N* values for all four effect sizes, with more pronounced differences at negligible and small effect sizes. However, the graphs converged to the same conclusion that large enough sample sizes could produce significant results at negligible and small effect sizes. 

Figure \@ref(fig:effects-graph-nonsig) portrays the results for non-significant binned simulations, which were the same for both $\alpha$ criterion. Across all effect sizes, BF and NHST showed similar results, where non-significant estimates were detected at lower sample sizes for negligible and small effect size simulations. At medium and large effect sizes, almost all estimates would have been considered significant, therefore, detection rates for non-significant estimates were around zero. OOM displayed a conservative set of findings, showing nearly 100% non-significant estimates at negligible and small effect sizes (mirroring results from Figure \@ref(fig:effects-graph-sig)). At medium effect sizes, approximately a quarter of estimates were non-significant, illustrating the conservative nature of OOM interpretations. 

```{r effects-graph-sig, echo=FALSE, fig.cap="Percent of significant estimates at $p$ < .05 (solid) and $p$ < .005 (dashed) for each analysis given effect size and sample size.", fig.height=8, fig.width=8}

library(reshape)
library(ggplot2)
library(cowplot)


#load graph data
Graph_05 = read.csv("Graph_data.05.csv")
Graph_005 = read.csv("Graph_data.005.csv")

Graph_data = cbind(Graph_05, Graph_005[ , 4:5])
colnames(Graph_data) = c("Effect","Significance", "N", "Parametric.05", "Non.Parametric.05", "Bayes", "OOM", "Parametric.005", "Non.Parametric.005")

##delete duplicate NS values, they don't change
Graph_data[ Graph_data$Significance == "Non", "Parametric.005" ] = NA
Graph_data[ Graph_data$Significance == "Non", "Non.Parametric.005" ] = NA

##drop NP because results are same as P, all results can been found online if you are interested
Graph_data = Graph_data[ , -c(5,9)]

##melt the data
long_graph = melt(Graph_data,
                  id = c("Effect","Significance","N"))
colnames(long_graph) = c("Effect","Significance", "N","Analysis","value")

cleanup = theme(panel.grid.major = element_blank(), 
              panel.grid.minor = element_blank(), 
              panel.background = element_blank(), 
              axis.line.x = element_line(colour = "black"), 
              axis.line.y = element_line(colour = "black"),
              legend.key = element_rect(fill = "white"),
              text = element_text(size = 11),
              axis.text.x = element_text(size = 9),
              axis.text.y = element_text(size = 9))

long_graph = na.omit(long_graph)
long_graph$Analysis = factor(long_graph$Analysis,
                             levels = c("Parametric.05", 
                                        "Parametric.005",
                                        "Bayes","OOM"),
                             labels = c("NHST .05",
                                        "NHST .005",
                                        "Bayes Factors","OOM"))

##log N scale 
long_graph$N = log(long_graph$N)

####sig findings graph####
sig_data = subset(long_graph, Significance=="Sig")
sig_data_large = subset(sig_data, Effect=="Large")

p1 = ggplot(sig_data_large) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Large Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Significant") +
  xlab("log(N)") + 
  cleanup +
  geom_point(data=sig_data_large,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 4) +
  scale_linetype_manual(values=c("solid", "dashed", "solid", "solid")) +
  scale_color_manual(values = c("gray50","gray50", "gray50","gray50")) + 
  scale_shape_manual(values = c(3, 4, 5, 6))

sig_data_medium = subset(sig_data, Effect=="Medium")
p2 = ggplot(sig_data_medium) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Medium Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Significant") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=sig_data_medium,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 4) +
  scale_linetype_manual(values=c("solid", "dashed", "solid", "solid")) +
  scale_color_manual(values = c("gray50","gray50", "gray50","gray50")) + 
  scale_shape_manual(values = c(3, 4, 5, 6))

sig_data_small = subset(sig_data, Effect=="Small")
p3 = ggplot(sig_data_small) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Small Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Significant") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=sig_data_small,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 4) +
  scale_linetype_manual(values=c("solid", "dashed", "solid", "solid")) +
  scale_color_manual(values = c("gray50","gray50", "gray50","gray50")) + 
  scale_shape_manual(values = c(3, 4, 5, 6))

sig_data_none = subset(sig_data, Effect=="None")
p4 = ggplot(sig_data_none) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Negligible Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Significant") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=sig_data_none,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 4) +
  scale_linetype_manual(values=c("solid", "dashed", "solid", "solid")) +
  scale_color_manual(values = c("gray50","gray50", "gray50","gray50")) + 
  scale_shape_manual(values = c(3, 4, 5, 6))

####put the graphs together####
legend = get_legend(p1)
prow <- plot_grid( p4 + theme(legend.position="none"),
                   p3 + theme(legend.position="none"),
                   p2 + theme(legend.position="none"),
                   p1 + theme(legend.position=c(.6,.25)),
                   hjust = -1,
                   nrow = 2
)
prow
```

```{r effects-graph-nonsig, echo=FALSE, fig.cap="Percent of non-significant effects for each analysis given effect size and sample size.", fig.height=8, fig.width=8}
###################################################### percent non-significant findings graphs
non_data = subset(long_graph, Significance=="Non")
non_data_large = subset(non_data, Effect=="Large")

a1 = ggplot(non_data_large) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Large Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Non-Significant") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=non_data_large,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 3)+
  scale_linetype_manual(values=c("solid", "solid","solid")) +
  scale_color_manual(values = c("gray50","gray50","gray50")) + 
  scale_shape_manual(values = c(3, 5, 6))

non_data_medium = subset(non_data, Effect=="Medium")
a2 = ggplot(non_data_medium) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Medium Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Perfect Non-Significant") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=non_data_medium,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 3)+
  scale_linetype_manual(values=c("solid", "solid","solid")) +
  scale_color_manual(values = c("gray50","gray50","gray50")) + 
  scale_shape_manual(values = c(3, 5, 6))

non_data_small = subset(non_data, Effect=="Small")
a3 = ggplot(non_data_small) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Small Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Non-Significant") +
  xlab("log(N)") + 
  cleanup +
  geom_point(data=non_data_small,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 3)+
  scale_linetype_manual(values=c("solid", "solid","solid")) +
  scale_color_manual(values = c("gray50","gray50","gray50")) + 
  scale_shape_manual(values = c(3, 5, 6))

non_data_none = subset(non_data, Effect=="None")
a4 = ggplot(non_data_none) + 
  geom_line(aes(x=N, 
                y=value, 
                group = Analysis,
                linetype = Analysis, 
                colour = Analysis),
            size=0.75) + 
  labs(title="Negligible Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Non-Significant") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=non_data_none,
             aes(x = N,
                 y = value,
                 shape = Analysis), 
             size = 3)+
  scale_linetype_manual(values=c("solid", "solid","solid")) +
  scale_color_manual(values = c("gray50","gray50","gray50")) + 
  scale_shape_manual(values = c(3, 5, 6))

####put the graphs together####
legend = get_legend(a1)
arow <- plot_grid( a4 + theme(legend.position="none"),
                   a3 + theme(legend.position="none"),
                   a2 + theme(legend.position="none"),
                   a1 + theme(legend.position=c(.6, .25)),
                   hjust = -1,
                   nrow = 2
)
arow
```

## Percent Agreement

A goal of this project was to expand the toolbox of options for researchers to determine what evidence supports their hypotheses by examining multiple methodologies. We calculated the percent of time that all analyses agreed across overall and *post hoc* comparison estimates. Figure \@ref(fig:agree-graph-omnibus) illustrates the pattern of 100% agreement on effects for critical omnibus tests only at each sample size and effect size.  Figure \@ref(fig:agree-graph-post) portrays the results for *post hoc* tests, which only uses NHST and Bayes Factor analyses, as OOM does not have a *post hoc* test (i.e., the test is a pattern analysis that presupposes the expected direction of *post hoc* tests).

When effect sizes were negligible and for small effects, agreement was best across small samples and decreased across sample size, as NHST was overly biased to report significant estimates and OOM and BF were less likely to do so. For medium and large effect sizes, 50-75% agreement was found, usually regardless of sample size. Additionally, we found that for negligible, small, and medium effects, agreement for *post hoc* tests was higher than agreement for overall comparisons. The *post hoc* comparisons for levels 1 to 2 and levels 2 to 3 were less likely to be binned as significant across negligible and small effects, so the agreement levels were higher for these individual comparisons due to non-significant follow up tests. The critical omnibus test was more likely to be significant due to the inclusion of effect of comparisons between level 1 and 3, which were double the effect size. However, these *post hoc* comparisons do not include the conservative significant binning from OOM, which decreased critical omnibus 100% agreement seen in Figure \@ref(fig:agree-graph-omnibus). Again, the differences between *p* < .05 and *p* < .005 were minimal. Complete tables of percentages of binning across critical omnibus and *post hoc* tests, along with agreement percentages broken down by bins can be found at https://osf.io/u9hf4/. 

```{r 100-agree-05, eval=FALSE, include=FALSE}

overall_sims <- read.csv("overall_sims.csv")
data = overall_sims

######################################################################################## Binning
#################################### Bin Omni P NHST
options(scipen=999)
data$BinOmniP = data$omniP
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.05, "significant")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.10, "marginal")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<=1, "non-sig")
data$BinOmniP = factor(data$BinOmniP, levels = c("non-sig","marginal","significant"))
table(data$BinOmniP)
################################# Bin Omni P NHST

################################# Bin 1v2 P NHST
data$Binp1v2 = data$p1v2
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.05, "significant")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.10, "marginal")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<=1, "non-sig")
data$Binp1v2 = factor(data$Binp1v2, levels = c("non-sig","marginal","significant"))
table(data$Binp1v2)
################################ Bin 1v2 P NHST

############################### Bin 1v3 P NHST
data$Binp1v3 = data$p1v3
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.05, "significant")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.10, "marginal")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<=1, "non-sig")
data$Binp1v3 = factor(data$Binp1v3, levels = c("non-sig","marginal","significant"))
table(data$Binp1v3)
############################### Bin 1v3 P NHST

############################# Bin 2v3 P NHST
data$Binp2v3 = data$p2v3
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.05, "significant")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.10, "marginal")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<=1, "non-sig")
data$Binp2v3 = factor(data$Binp2v3, levels = c("non-sig","marginal","significant"))
table(data$Binp2v3)
############################ Bin 2v3 P NHST

############################# Bin omni quades P
data$BinquadeP = data$quadeP
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.05, "significant")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.10, "marginal")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<=1, "non-sig")
data$BinquadeP = factor(data$BinquadeP, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP)
############################ Bin omni quades P

############################# Bin quade P 1v2
data$BinquadeP1v2 = data$quadeP1v2
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.05, "significant")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.10, "marginal")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<=1, "non-sig")
data$BinquadeP1v2 = factor(data$BinquadeP1v2, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v2)
############################ Bin quade P 1v2

############################ Bin quade P 1v3
data$BinquadeP1v3 = data$quadeP1v3
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.05, "significant")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.10, "marginal")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<=1, "non-sig")
data$BinquadeP1v3 = factor(data$BinquadeP1v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v3)
########################### Bin quade P 1v3

############################ Bin quade P 2v3
data$BinquadeP2v3 = data$quadeP2v3
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.05, "significant")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.10, "marginal")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<=1, "non-sig")
data$BinquadeP2v3 = factor(data$BinquadeP2v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP2v3)
########################### Bin quade P 2v3


########################## Bin overall BF
data$BinoverallBF = data$overallBF
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<3, "weak")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<20, "positive")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<=Inf, "strong")
data$BinoverallBF = factor(data$BinoverallBF, levels = c("weak","positive","strong"))
table(data$BinoverallBF)
######################### Bin overall BF

########################## Bin BF 1v2
data$BinBF1v2 = data$BF1v2
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<3, "weak")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<20, "positive")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<=Inf, "strong")
data$BinBF1v2 = factor(data$BinBF1v2, levels = c("weak","positive","strong"))
table(data$BinBF1v2)
######################### Bin BF 1v2

########################## Bin BF 1v3
data$BinBF1v3 = data$BF1v3
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<3, "weak")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<20, "positive")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<=Inf, "strong")
data$BinBF1v3 = factor(data$BinBF1v3, levels = c("weak","positive","strong"))
table(data$BinBF1v3)
######################### Bin BF 1v3

######################### Bin BF 2v3
data$BinBF2v3 = data$BF2v3
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<3, "weak")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<20, "positive")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<=Inf, "strong")
data$BinBF2v3 = factor(data$BinBF2v3, levels = c("weak","positive","strong"))
table(data$BinBF2v3)
######################### Bin BF 2v3

######################### Bin stdev
data$stdev = replace(data$stdev, data$stdev==0.1, "Large")
data$stdev = replace(data$stdev, data$stdev==0.5, "Medium")
data$stdev = replace(data$stdev, data$stdev== 3,  "Small")
data$stdev = replace(data$stdev, data$stdev==11.5, "None")
table(data$stdev)
######################### Bin stdev


########################### Bin oom chance
data$Binoomchance = data$oomchance
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.05, "low")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.10, "medium")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<=1, "high")
data$Binoomchance = factor(data$Binoomchance, levels = c("high","medium","low"))
table(data$Binoomchance)

data$Binoompcc = data$oompcc
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<0.50, "low")
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<1.01, "high")
table(data$Binoompcc)

data$Binoom = 0
round = 0
nsim = nrow(data)

for(i in 1:nsim){
  round = round+1
  if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="low"){
    data$Binoom[round] = "significant"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="medium"){
    data$Binoom[round] = "marginal"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="high"){
    data$Binoom[round] = "non-sig"
  } else if(data$Binoompcc[round]=="low"){
    data$Binoom[round] = "non-sig"
  }
}
data$Binoom = factor(data$Binoom, levels = c("non-sig","marginal","significant"))
table(data$Binoom)
########################### Bin oom chance

######################################################################################## Binning



################################################################## percent agree
######################## percent 100% agree ES Large
pAgree_Large = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Large) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_Large[1,1] = 10
pAgree_Large[2,1] = 30
pAgree_Large[3,1] = 100
pAgree_Large[4,1] = 500
pAgree_Large[5,1] = 1000

pAgree_Sig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_Large) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_Large[1,1] = 10
pAgree_Sig_Large[2,1] = 30
pAgree_Sig_Large[3,1] = 100
pAgree_Sig_Large[4,1] = 500
pAgree_Sig_Large[5,1] = 1000

pAgree_Nonsig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_Large) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_Large[1,1] = 10
pAgree_Nonsig_Large[2,1] = 30
pAgree_Nonsig_Large[3,1] = 100
pAgree_Nonsig_Large[4,1] = 500
pAgree_Nonsig_Large[5,1] = 1000

largedata = subset(data, stdev=="Large")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,2] = 0
    pAgree_Nonsig_Large[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,2] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,3] = 0
    pAgree_Nonsig_Large[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,3] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,4] = 0
    pAgree_Nonsig_Large[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,4] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,5] = 0
    pAgree_Nonsig_Large[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,5] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES Large



######################## percent 100% agree ES Medium
pAgree_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Medium) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_Medium[1,1] = 10
pAgree_Medium[2,1] = 30
pAgree_Medium[3,1] = 100
pAgree_Medium[4,1] = 500
pAgree_Medium[5,1] = 1000

pAgree_Sig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_Medium) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_Medium[1,1] = 10
pAgree_Sig_Medium[2,1] = 30
pAgree_Sig_Medium[3,1] = 100
pAgree_Sig_Medium[4,1] = 500
pAgree_Sig_Medium[5,1] = 1000

pAgree_Nonsig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_Medium) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_Medium[1,1] = 10
pAgree_Nonsig_Medium[2,1] = 30
pAgree_Nonsig_Medium[3,1] = 100
pAgree_Nonsig_Medium[4,1] = 500
pAgree_Nonsig_Medium[5,1] = 1000

Mediumdata = subset(data, stdev=="Medium")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,2] = 0
    pAgree_Nonsig_Medium[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,2] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,3] = 0
    pAgree_Nonsig_Medium[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,3] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,4] = 0
    pAgree_Nonsig_Medium[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,4] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,5] = 0
    pAgree_Nonsig_Medium[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,5] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES Medium



######################## percent 100% agree ES Small
pAgree_Small = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Small) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_Small[1,1] = 10
pAgree_Small[2,1] = 30
pAgree_Small[3,1] = 100
pAgree_Small[4,1] = 500
pAgree_Small[5,1] = 1000

pAgree_Sig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_Small) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_Small[1,1] = 10
pAgree_Sig_Small[2,1] = 30
pAgree_Sig_Small[3,1] = 100
pAgree_Sig_Small[4,1] = 500
pAgree_Sig_Small[5,1] = 1000

pAgree_Nonsig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_Small) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_Small[1,1] = 10
pAgree_Nonsig_Small[2,1] = 30
pAgree_Nonsig_Small[3,1] = 100
pAgree_Nonsig_Small[4,1] = 500
pAgree_Nonsig_Small[5,1] = 1000

Smalldata = subset(data, stdev=="Small")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,2] = 0
    pAgree_Nonsig_Small[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,2] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,3] = 0
    pAgree_Nonsig_Small[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,3] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,4] = 0
    pAgree_Nonsig_Small[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,4] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,5] = 0
    pAgree_Nonsig_Small[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,5] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES Small



######################## percent 100% agree ES None
pAgree_None = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_None) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_None[1,1] = 10
pAgree_None[2,1] = 30
pAgree_None[3,1] = 100
pAgree_None[4,1] = 500
pAgree_None[5,1] = 1000

pAgree_Sig_None = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_None) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_None[1,1] = 10
pAgree_Sig_None[2,1] = 30
pAgree_Sig_None[3,1] = 100
pAgree_Sig_None[4,1] = 500
pAgree_Sig_None[5,1] = 1000

pAgree_Nonsig_None = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_None) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_None[1,1] = 10
pAgree_Nonsig_None[2,1] = 30
pAgree_Nonsig_None[3,1] = 100
pAgree_Nonsig_None[4,1] = 500
pAgree_Nonsig_None[5,1] = 1000

Nonedata = subset(data, stdev=="None")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,2] = 0
    pAgree_Nonsig_None[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,2] = x1_tab[3]
    pAgree_Nonsig_None[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,3] = 0
    pAgree_Nonsig_None[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,3] = x1_tab[3]
    pAgree_Nonsig_None[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,4] = 0
    pAgree_Nonsig_None[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,4] = x1_tab[3]
    pAgree_Nonsig_None[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,5] = 0
    pAgree_Nonsig_None[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,5] = x1_tab[3]
    pAgree_Nonsig_None[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES None 
################################################################## percent agree

pAgree_Large$Effect = "Large"
pAgree_Large = pAgree_Large[ , c(6,1,2,3,4,5)]
pAgree_Medium$Effect = "Medium"
pAgree_Medium = pAgree_Medium[ , c(6,1,2,3,4,5)]
pAgree_Small$Effect = "Small"
pAgree_Small = pAgree_Small[ , c(6,1,2,3,4,5)]
pAgree_None$Effect = "None"
pAgree_None = pAgree_None[ , c(6,1,2,3,4,5)]
Percent100agree = rbind(pAgree_Large, pAgree_Medium,
                        pAgree_Small, pAgree_None)

pAgree_Sig_Large$Effect = "Large"
pAgree_Sig_Large = pAgree_Sig_Large[ , c(6,1,2,3,4,5)]
pAgree_Sig_Medium$Effect = "Medium"
pAgree_Sig_Medium = pAgree_Sig_Medium[ , c(6,1,2,3,4,5)]
pAgree_Sig_Small$Effect = "Small"
pAgree_Sig_Small = pAgree_Sig_Small[ , c(6,1,2,3,4,5)]
pAgree_Sig_None$Effect = "None"
pAgree_Sig_None = pAgree_Sig_None[ , c(6,1,2,3,4,5)]
PercentOfAgreementIsSig = rbind(pAgree_Sig_Large, pAgree_Sig_Medium,
                        pAgree_Sig_Small, pAgree_Sig_None)

pAgree_Nonsig_Large$Effect = "Large"
pAgree_Nonsig_Large = pAgree_Nonsig_Large[ , c(6,1,2,3,4,5)]
pAgree_Nonsig_Medium$Effect = "Medium"
pAgree_Nonsig_Medium = pAgree_Nonsig_Medium[ , c(6,1,2,3,4,5)]
pAgree_Nonsig_Small$Effect = "Small"
pAgree_Nonsig_Small = pAgree_Nonsig_Small[ , c(6,1,2,3,4,5)]
pAgree_Nonsig_None$Effect = "None"
pAgree_Nonsig_None = pAgree_Nonsig_None[ , c(6,1,2,3,4,5)]
PercentOfAgreementIsNonSig = rbind(pAgree_Nonsig_Large, pAgree_Nonsig_Medium,
                                pAgree_Nonsig_Small, pAgree_Nonsig_None)

write.csv(Percent100agree, file = "Percent100Agree.05.csv")
write.csv(PercentOfAgreementIsSig, file = "PercentIsSig.05.csv")
write.csv(PercentOfAgreementIsNonSig, file = "PercentIsNonSig.05.csv")
```

```{r 100-agree-005, eval=FALSE, include=FALSE}

overall_sims <- read.csv("overall_sims.csv")
data = overall_sims

######################################################################################## Binning
#################################### Bin Omni P NHST
options(scipen=999)
data$BinOmniP = data$omniP
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.005, "significant")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<0.10, "marginal")
data$BinOmniP = replace(data$BinOmniP, data$BinOmniP<=1, "non-sig")
data$BinOmniP = factor(data$BinOmniP, levels = c("non-sig","marginal","significant"))
table(data$BinOmniP)
################################# Bin Omni P NHST

################################# Bin 1v2 P NHST
data$Binp1v2 = data$p1v2
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.005, "significant")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<0.10, "marginal")
data$Binp1v2 = replace(data$Binp1v2, data$Binp1v2<=1, "non-sig")
data$Binp1v2 = factor(data$Binp1v2, levels = c("non-sig","marginal","significant"))
table(data$Binp1v2)
################################ Bin 1v2 P NHST

############################### Bin 1v3 P NHST
data$Binp1v3 = data$p1v3
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.005, "significant")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<0.10, "marginal")
data$Binp1v3 = replace(data$Binp1v3, data$Binp1v3<=1, "non-sig")
data$Binp1v3 = factor(data$Binp1v3, levels = c("non-sig","marginal","significant"))
table(data$Binp1v3)
############################### Bin 1v3 P NHST

############################# Bin 2v3 P NHST
data$Binp2v3 = data$p2v3
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.005, "significant")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<0.10, "marginal")
data$Binp2v3 = replace(data$Binp2v3, data$Binp2v3<=1, "non-sig")
data$Binp2v3 = factor(data$Binp2v3, levels = c("non-sig","marginal","significant"))
table(data$Binp2v3)
############################ Bin 2v3 P NHST

############################# Bin omni quades P
data$BinquadeP = data$quadeP
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.005, "significant")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<0.10, "marginal")
data$BinquadeP = replace(data$BinquadeP, data$BinquadeP<=1, "non-sig")
data$BinquadeP = factor(data$BinquadeP, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP)
############################ Bin omni quades P

############################# Bin quade P 1v2
data$BinquadeP1v2 = data$quadeP1v2
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.005, "significant")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<0.10, "marginal")
data$BinquadeP1v2 = replace(data$BinquadeP1v2, data$BinquadeP1v2<=1, "non-sig")
data$BinquadeP1v2 = factor(data$BinquadeP1v2, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v2)
############################ Bin quade P 1v2

############################ Bin quade P 1v3
data$BinquadeP1v3 = data$quadeP1v3
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.005, "significant")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<0.10, "marginal")
data$BinquadeP1v3 = replace(data$BinquadeP1v3, data$BinquadeP1v3<=1, "non-sig")
data$BinquadeP1v3 = factor(data$BinquadeP1v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP1v3)
########################### Bin quade P 1v3

############################ Bin quade P 2v3
data$BinquadeP2v3 = data$quadeP2v3
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.005, "significant")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<0.10, "marginal")
data$BinquadeP2v3 = replace(data$BinquadeP2v3, data$BinquadeP2v3<=1, "non-sig")
data$BinquadeP2v3 = factor(data$BinquadeP2v3, levels = c("non-sig","marginal","significant"))
table(data$BinquadeP2v3)
########################### Bin quade P 2v3


########################## Bin overall BF
data$BinoverallBF = data$overallBF
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<3, "weak")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<20, "positive")
data$BinoverallBF = replace(data$BinoverallBF, data$BinoverallBF<=Inf, "strong")
data$BinoverallBF = factor(data$BinoverallBF, levels = c("weak","positive","strong"))
table(data$BinoverallBF)
######################### Bin overall BF

########################## Bin BF 1v2
data$BinBF1v2 = data$BF1v2
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<3, "weak")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<20, "positive")
data$BinBF1v2 = replace(data$BinBF1v2, data$BinBF1v2<=Inf, "strong")
data$BinBF1v2 = factor(data$BinBF1v2, levels = c("weak","positive","strong"))
table(data$BinBF1v2)
######################### Bin BF 1v2

########################## Bin BF 1v3
data$BinBF1v3 = data$BF1v3
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<3, "weak")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<20, "positive")
data$BinBF1v3 = replace(data$BinBF1v3, data$BinBF1v3<=Inf, "strong")
data$BinBF1v3 = factor(data$BinBF1v3, levels = c("weak","positive","strong"))
table(data$BinBF1v3)
######################### Bin BF 1v3

######################### Bin BF 2v3
data$BinBF2v3 = data$BF2v3
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<3, "weak")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<20, "positive")
data$BinBF2v3 = replace(data$BinBF2v3, data$BinBF2v3<=Inf, "strong")
data$BinBF2v3 = factor(data$BinBF2v3, levels = c("weak","positive","strong"))
table(data$BinBF2v3)
######################### Bin BF 2v3

######################### Bin stdev
data$stdev = replace(data$stdev, data$stdev==0.1, "Large")
data$stdev = replace(data$stdev, data$stdev==0.5, "Medium")
data$stdev = replace(data$stdev, data$stdev== 3,  "Small")
data$stdev = replace(data$stdev, data$stdev==11.5, "None")
table(data$stdev)
######################### Bin stdev


########################### Bin oom chance
data$Binoomchance = data$oomchance
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.05, "low")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<0.10, "medium")
data$Binoomchance = replace(data$Binoomchance, data$Binoomchance<=1, "high")
data$Binoomchance = factor(data$Binoomchance, levels = c("high","medium","low"))
table(data$Binoomchance)

data$Binoompcc = data$oompcc
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<0.50, "low")
data$Binoompcc = replace(data$Binoompcc, data$Binoompcc<1.01, "high")
table(data$Binoompcc)

data$Binoom = 0
round = 0
nsim = nrow(data)

for(i in 1:nsim){
  round = round+1
  if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="low"){
    data$Binoom[round] = "significant"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="medium"){
    data$Binoom[round] = "marginal"
  } else if(data$Binoompcc[round]=="high" && data$Binoomchance[round]=="high"){
    data$Binoom[round] = "non-sig"
  } else if(data$Binoompcc[round]=="low"){
    data$Binoom[round] = "non-sig"
  }
}
data$Binoom = factor(data$Binoom, levels = c("non-sig","marginal","significant"))
table(data$Binoom)
########################### Bin oom chance

######################################################################################## Binning



################################################################## percent agree
######################## percent 100% agree ES Large
pAgree_Large = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Large) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_Large[1,1] = 10
pAgree_Large[2,1] = 30
pAgree_Large[3,1] = 100
pAgree_Large[4,1] = 500
pAgree_Large[5,1] = 1000

pAgree_Sig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_Large) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_Large[1,1] = 10
pAgree_Sig_Large[2,1] = 30
pAgree_Sig_Large[3,1] = 100
pAgree_Sig_Large[4,1] = 500
pAgree_Sig_Large[5,1] = 1000

pAgree_Nonsig_Large = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_Large) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_Large[1,1] = 10
pAgree_Nonsig_Large[2,1] = 30
pAgree_Nonsig_Large[3,1] = 100
pAgree_Nonsig_Large[4,1] = 500
pAgree_Nonsig_Large[5,1] = 1000

largedata = subset(data, stdev=="Large")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,2] = 0
    pAgree_Nonsig_Large[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,2] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,3] = 0
    pAgree_Nonsig_Large[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,3] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,4] = 0
    pAgree_Nonsig_Large[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,4] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(largedata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Large[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Large[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_Large[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Large[xrun,5] = 0
    pAgree_Nonsig_Large[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Large[xrun,5] = x1_tab[3]
    pAgree_Nonsig_Large[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES Large



######################## percent 100% agree ES Medium
pAgree_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Medium) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_Medium[1,1] = 10
pAgree_Medium[2,1] = 30
pAgree_Medium[3,1] = 100
pAgree_Medium[4,1] = 500
pAgree_Medium[5,1] = 1000

pAgree_Sig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_Medium) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_Medium[1,1] = 10
pAgree_Sig_Medium[2,1] = 30
pAgree_Sig_Medium[3,1] = 100
pAgree_Sig_Medium[4,1] = 500
pAgree_Sig_Medium[5,1] = 1000

pAgree_Nonsig_Medium = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_Medium) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_Medium[1,1] = 10
pAgree_Nonsig_Medium[2,1] = 30
pAgree_Nonsig_Medium[3,1] = 100
pAgree_Nonsig_Medium[4,1] = 500
pAgree_Nonsig_Medium[5,1] = 1000

Mediumdata = subset(data, stdev=="Medium")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,2] = 0
    pAgree_Nonsig_Medium[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,2] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,3] = 0
    pAgree_Nonsig_Medium[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,3] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,4] = 0
    pAgree_Nonsig_Medium[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,4] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Mediumdata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Medium[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Medium[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_Medium[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Medium[xrun,5] = 0
    pAgree_Nonsig_Medium[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Medium[xrun,5] = x1_tab[3]
    pAgree_Nonsig_Medium[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES Medium



######################## percent 100% agree ES Small
pAgree_Small = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Small) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_Small[1,1] = 10
pAgree_Small[2,1] = 30
pAgree_Small[3,1] = 100
pAgree_Small[4,1] = 500
pAgree_Small[5,1] = 1000

pAgree_Sig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_Small) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_Small[1,1] = 10
pAgree_Sig_Small[2,1] = 30
pAgree_Sig_Small[3,1] = 100
pAgree_Sig_Small[4,1] = 500
pAgree_Sig_Small[5,1] = 1000

pAgree_Nonsig_Small = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_Small) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_Small[1,1] = 10
pAgree_Nonsig_Small[2,1] = 30
pAgree_Nonsig_Small[3,1] = 100
pAgree_Nonsig_Small[4,1] = 500
pAgree_Nonsig_Small[5,1] = 1000

Smalldata = subset(data, stdev=="Small")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,2] = 0
    pAgree_Nonsig_Small[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,2] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,3] = 0
    pAgree_Nonsig_Small[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,3] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,4] = 0
    pAgree_Nonsig_Small[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,4] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Smalldata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_Small[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_Small[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_Small[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_Small[xrun,5] = 0
    pAgree_Nonsig_Small[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_Small[xrun,5] = x1_tab[3]
    pAgree_Nonsig_Small[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES Small



######################## percent 100% agree ES None
pAgree_None = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_None) = c("N","Omnibus", "1v2", "1v3","2v3")
pAgree_None[1,1] = 10
pAgree_None[2,1] = 30
pAgree_None[3,1] = 100
pAgree_None[4,1] = 500
pAgree_None[5,1] = 1000

pAgree_Sig_None = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Sig_None) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Sig_None[1,1] = 10
pAgree_Sig_None[2,1] = 30
pAgree_Sig_None[3,1] = 100
pAgree_Sig_None[4,1] = 500
pAgree_Sig_None[5,1] = 1000

pAgree_Nonsig_None = as.data.frame(matrix(0, nrow = 5, ncol = 5))
names(pAgree_Nonsig_None) = c("N","Omnibus", "1v2","1v3","2v3")
pAgree_Nonsig_None[1,1] = 10
pAgree_Nonsig_None[2,1] = 30
pAgree_Nonsig_None[3,1] = 100
pAgree_Nonsig_None[4,1] = 500
pAgree_Nonsig_None[5,1] = 1000

Nonedata = subset(data, stdev=="None")
library(stringr)
######## Overall
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempoverallBF = overallmatch$BinoverallBF
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"weak","non-sig")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"positive","marginal")
  overallmatch$tempoverallBF = str_replace_all(overallmatch$tempoverallBF,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$BinOmniP[round]==overallmatch$BinquadeP[round] &&
       overallmatch$BinOmniP[round]==overallmatch$Binoom[round] &&
       overallmatch$BinOmniP[round]==overallmatch$tempoverallBF[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$Binoom[round] &&
       #overallmatch$BinquadeP[round]==overallmatch$tempoverallBF[round] &&
       overallmatch$Binoom[round]==overallmatch$tempoverallBF[round]){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,2] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,2] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,2] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,2] = 0
    pAgree_Nonsig_None[xrun,2] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,2] = x1_tab[3]
    pAgree_Nonsig_None[xrun,2] = x1_tab[1]
  }
}
######## Overall

########### 1v2
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempBF1v2 = overallmatch$BinBF1v2
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"weak","non-sig")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"positive","marginal")
  overallmatch$tempBF1v2 = str_replace_all(overallmatch$tempBF1v2,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v2[round]==overallmatch$BinquadeP1v2[round] &&
       overallmatch$Binp1v2[round]==overallmatch$tempBF1v2[round] 
       #&& overallmatch$BinquadeP1v2[round]==overallmatch$tempBF1v2[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,3] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,3] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,3] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,3] = 0
    pAgree_Nonsig_None[xrun,3] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,3] = x1_tab[3]
    pAgree_Nonsig_None[xrun,3] = x1_tab[1]
  }
}
########### 1v2

########### 1v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempBF1v3 = overallmatch$BinBF1v3
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"weak","non-sig")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"positive","marginal")
  overallmatch$tempBF1v3 = str_replace_all(overallmatch$tempBF1v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp1v3[round]==overallmatch$BinquadeP1v3[round] &&
       overallmatch$Binp1v3[round]==overallmatch$tempBF1v3[round] 
       #&& overallmatch$BinquadeP1v3[round]==overallmatch$tempBF1v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,4] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,4] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,4] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,4] = 0
    pAgree_Nonsig_None[xrun,4] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,4] = x1_tab[3]
    pAgree_Nonsig_None[xrun,4] = x1_tab[1]
  }
}
########### 1v3

########### 2v3
matchN = c(10,30,100,500,1000)
xrun=0
for(i in 1:length(matchN)){
  place = matchN[i]
  xrun=xrun+1
  overallmatch = subset(Nonedata, N==place)
  #make BF match
  overallmatch$tempBF2v3 = overallmatch$BinBF2v3
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"weak","non-sig")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"positive","marginal")
  overallmatch$tempBF2v3 = str_replace_all(overallmatch$tempBF2v3,"strong","significant")
  nsim = 1000
  round=0
  overallmatch$percentAgreeOverall = "NA"
  for(j in 1:nsim){
    round=round+1
    if(#overallmatch$Binp2v3[round]==overallmatch$BinquadeP2v3[round] &&
       overallmatch$Binp2v3[round]==overallmatch$tempBF2v3[round] 
       #&& overallmatch$BinquadeP2v3[round]==overallmatch$tempBF2v3[round]
       ){
      
      overallmatch$percentAgreeOverall[round] = "Agree"
    } else{
      overallmatch$percentAgreeOverall[round] = "No"
    }
  }
  temp = (table(overallmatch$percentAgreeOverall)/sum(table(overallmatch$percentAgreeOverall)))*100
  if(length(temp) == 1 && names(temp[1]) == "Agree"){
    pAgree_None[xrun,5] = temp[1]
  } else if(length(temp) == 1 && names(temp[1]) != "Agree"){
    pAgree_None[xrun,5] = 0
  } else if(length(temp) > 1){
    pAgree_None[xrun,5] = temp[1]
  }
  #### sig/nonsig agree
  x1 = subset(overallmatch, percentAgreeOverall=="Agree")
  if(nrow(x1)==0){
    pAgree_Sig_None[xrun,5] = 0
    pAgree_Nonsig_None[xrun,5] = 0
  } else{
    x1$s_ns = x1$BinOmniP
    x1_tab = (table(x1$s_ns)/(sum(table(x1$s_ns))))*100
    pAgree_Sig_None[xrun,5] = x1_tab[3]
    pAgree_Nonsig_None[xrun,5] = x1_tab[1]
  }
}
########### 2v3
######################## percent 100% agree ES None 
################################################################## percent agree

pAgree_Large$Effect = "Large"
pAgree_Large = pAgree_Large[ , c(6,1,2,3,4,5)]
pAgree_Medium$Effect = "Medium"
pAgree_Medium = pAgree_Medium[ , c(6,1,2,3,4,5)]
pAgree_Small$Effect = "Small"
pAgree_Small = pAgree_Small[ , c(6,1,2,3,4,5)]
pAgree_None$Effect = "None"
pAgree_None = pAgree_None[ , c(6,1,2,3,4,5)]
Percent100agree = rbind(pAgree_Large, pAgree_Medium,
                        pAgree_Small, pAgree_None)

pAgree_Sig_Large$Effect = "Large"
pAgree_Sig_Large = pAgree_Sig_Large[ , c(6,1,2,3,4,5)]
pAgree_Sig_Medium$Effect = "Medium"
pAgree_Sig_Medium = pAgree_Sig_Medium[ , c(6,1,2,3,4,5)]
pAgree_Sig_Small$Effect = "Small"
pAgree_Sig_Small = pAgree_Sig_Small[ , c(6,1,2,3,4,5)]
pAgree_Sig_None$Effect = "None"
pAgree_Sig_None = pAgree_Sig_None[ , c(6,1,2,3,4,5)]
PercentOfAgreementIsSig = rbind(pAgree_Sig_Large, pAgree_Sig_Medium,
                                pAgree_Sig_Small, pAgree_Sig_None)

pAgree_Nonsig_Large$Effect = "Large"
pAgree_Nonsig_Large = pAgree_Nonsig_Large[ , c(6,1,2,3,4,5)]
pAgree_Nonsig_Medium$Effect = "Medium"
pAgree_Nonsig_Medium = pAgree_Nonsig_Medium[ , c(6,1,2,3,4,5)]
pAgree_Nonsig_Small$Effect = "Small"
pAgree_Nonsig_Small = pAgree_Nonsig_Small[ , c(6,1,2,3,4,5)]
pAgree_Nonsig_None$Effect = "None"
pAgree_Nonsig_None = pAgree_Nonsig_None[ , c(6,1,2,3,4,5)]
PercentOfAgreementIsNonSig = rbind(pAgree_Nonsig_Large, pAgree_Nonsig_Medium,
                                   pAgree_Nonsig_Small, pAgree_Nonsig_None)

write.csv(Percent100agree, file = "Percent100Agree.005.csv")
write.csv(PercentOfAgreementIsSig, file = "PercentIsSig.005.csv")
write.csv(PercentOfAgreementIsNonSig, file = "PercentIsNonSig.005.csv")

```

```{r agree-graph-omnibus, echo=FALSE, fig.cap="Percent of agreement across each analysis given effect size and sample size for omnnibus tests.", fig.height=8, fig.width=8}

agree = read.csv("Graph_data_agree.05.csv")
agree2 = read.csv("Graph_data_agree.005.csv")
agree_together = cbind(agree, agree2[ , -c(1:2)])
colnames(agree_together) = c("effect", "N", "omnibus.05",
                             "onetotwo.05", "twotothree.05",
                             "omnibus.005", "onetotwo.005", 
                             "twotothree.005")

agreelong = melt(agree_together,
                 id = c("effect", "N"))
colnames(agreelong)[3:4] = c("comparison", "percent")

##log n to get a better graph
agreelong$N = log(agreelong$N)

##just omnibus tests
agreelong = subset(agreelong, comparison == "omnibus.05" | 
                     comparison == "omnibus.005")

agree_large = subset(agreelong, effect == "Large")
w1 = ggplot(agree_large) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Large Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=agree_large,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        labels = c(".05", ".005"),
                        values=c("solid","solid")) +
  scale_color_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c("gray50","gray50")) + 
  scale_shape_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c(3, 4))

agree_medium = subset(agreelong, effect == "Medium")
w2 = ggplot(agree_medium) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Medium Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=agree_medium,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        labels = c(".05", ".005"),
                        values=c("solid","solid")) +
  scale_color_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c("gray50","gray50")) + 
  scale_shape_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c(3, 4))

agree_small = subset(agreelong, effect == "Small")
w3 = ggplot(agree_small) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Small Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=agree_small,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        labels = c(".05", ".005"),
                        values=c("solid","solid")) +
  scale_color_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c("gray50","gray50")) + 
  scale_shape_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c(3, 4))

agree_none = subset(agreelong, effect == "None")
w4 = ggplot(agree_none) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Negligible Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") + 
  cleanup +
  geom_point(data=agree_none,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        labels = c(".05", ".005"),
                        values=c("solid","solid")) +
  scale_color_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c("gray50","gray50")) + 
  scale_shape_manual(name = "Comparison", 
                     labels = c(".05", ".005"),
                     values = c(3, 4))

####put the graphs together####
legend = get_legend(w1)
wrow <- plot_grid( w4 + theme(legend.position="none"),
                   w3 + theme(legend.position="none"),
                   w2 + theme(legend.position="none"),
                   w1 + theme(legend.position=c(.6,.25)),
                   hjust = -1,
                   nrow = 2
)
wrow
```

```{r agree-graph-post, echo=FALSE, fig.cap="Percent of agreement across each analysis given effect size and sample size $post hoc$ tests with $p$ < .05 (solid) and $p$ < .005 (dashed).", fig.height=8, fig.width=8}

agreelong = melt(agree_together,
                 id = c("effect", "N"))
colnames(agreelong)[3:4] = c("comparison", "percent")

##just omnibus tests
agreelong = subset(agreelong, comparison != "omnibus.05" & 
                     comparison != "omnibus.005")

agreelong$comparison = factor(agreelong$comparison,
                              levels = c("onetotwo.05", "twotothree.05",
                                         "onetotwo.005", "twotothree.005"),
                              labels = c("1-2 .05", "2-3 .05",
                                         "1-2 .005", "2-3 .005"))

agree_large = subset(agreelong, effect == "Large")
w11 = ggplot(agree_large) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Large Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") +
  cleanup +
  geom_point(data=agree_large,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        values=c("solid", "solid","dashed", "dashed")) +
  scale_color_manual(name = "Comparison",
                     values = c("gray50","gray50","gray", "gray")) + 
  scale_shape_manual(name = "Comparison",
                     values = c(3, 4, 3, 4))

agree_medium = subset(agreelong, effect == "Medium")
w21 = ggplot(agree_medium) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Medium Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") +
  xlab("log(N)") +
  cleanup +
  geom_point(data=agree_medium,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        values=c("solid", "solid","dashed", "dashed")) +
  scale_color_manual(name = "Comparison",
                     values = c("gray50","gray50","gray", "gray")) + 
  scale_shape_manual(name = "Comparison",
                     values = c(3, 4, 3, 4))

agree_small = subset(agreelong, effect == "Small")
w31 = ggplot(agree_small) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Small Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") +
  cleanup +
  geom_point(data=agree_small,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        values=c("solid", "solid","dashed", "dashed")) +
  scale_color_manual(name = "Comparison",
                     values = c("gray50","gray50","gray", "gray")) + 
  scale_shape_manual(name = "Comparison",
                     values = c(3, 4, 3, 4))

agree_none = subset(agreelong, effect == "None")
w41 = ggplot(agree_none) + 
  geom_line(aes(x=N, 
                y=percent, 
                group = comparison,
                linetype = comparison, 
                colour = comparison),
            size=0.75) + 
  labs(title="Negligible Effects") +
  coord_cartesian(ylim = c(0,101)) + 
  ylab("Percent Agreement") + 
  xlab("log(N)") +
  cleanup +
  geom_point(data=agree_none,
             aes(x = N,
                 y = percent,
                 shape = comparison), 
             size = 4) +
  scale_linetype_manual(name = "Comparison", 
                        values=c("solid", "solid","dashed", "dashed")) +
  scale_color_manual(name = "Comparison",
                     values = c("gray50","gray50","gray", "gray")) + 
  scale_shape_manual(name = "Comparison",
                     values = c(3, 4, 3, 4))

####put the graphs together####
legend = get_legend(w11)
wrow1 <- plot_grid( w41 + theme(legend.position="none"),
                   w31 + theme(legend.position="none"),
                   w21 + theme(legend.position="none"),
                   w11 + theme(legend.position=c(.6,.25)),
                   hjust = -1,
                   nrow = 2
)
wrow1
```

## Criterion Comparison

As the relationship between BF and *p*-values is already well documented, we will not discuss them here beyond stating that we found the expected pattern shown in previous work [@Rouder2012], and that individuals who wish to view this comparison, as well as all the other comparisons discussed here should visit our interactive Shiny application at our OSF page. Of interest was the comparison of OOM indices to traditional NHST and Bayesian indices. First, in Figure \@ref(fig:pcc-bf-fig), PCC values are plotted against log BF values and $p$-values. The log of BF was taken to include all values on a viewable axis, and all infinity values were windsorized to the next highest point. Increasing sample size is shown by increasing point size and lighter colors. Additionally, since OOM values are a combination of PCC and $c$-values, $c$-values below .05 are shown as Xs instead of dots. Therefore, all values PCC >= .50 that are also denoted as Xs would be considered significant in this example. The provided Shiny application uses color to distinguish sample size differences, as well as includes options to create each combination effect size and criterion individually. Only two graphs are provided here to save space. 

```{r pcc-bf-fig, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="PCC and c-values plotted against $p$ and BF values for negligible and medium effect size conditions. Xs indicate simulations with $c$-values < .05,which were binned as significant if they were found in conjunction with PCC values over .50. Point size and color indicates sample size wherein larger samples are lighter colors. Please note that the key for the entire set of graphics is in the bottom right hand corner.", fig.width=8, fig.height=8}
comparedata = read.csv("overall_sims_shiny.csv")
comparedata$N = factor(comparedata$N)
##deal with Inf BF values
large = length(unique(comparedata$overallBF))
comparedata$overallBF[is.infinite(comparedata$overallBF)] = sort(unique(comparedata$overallBF))[large-1]
comparedata$overallBF = log(comparedata$overallBF)

##create starred oomchance values
comparedata$star = as.factor(as.numeric(comparedata$oomchance <=.05))

##select only none data
comparenone = subset(comparedata, stdev == 11.5)
comparemed = subset(comparedata, stdev == .5)

pccbfnone = ggplot(comparenone, aes(oompcc, overallBF)) + 
         cleanup +
         geom_point(data = comparenone, aes(shape = star, size = N, color = N)) +
         xlab("OOM PCC Value") + 
         ylab("log(Bayes Factor)") +
         scale_shape_manual(name = "c-Value",
                              labels = c(">.05", "<=.05"),
                              values = c(16,4)) +
        scale_color_grey() +
        labs(title="Negligible Effects") +
        scale_x_continuous(labels = numform::ff_num(zero = 0))

pccbfmed = ggplot(comparemed, aes(oompcc, overallBF)) + 
         cleanup +
         geom_point(data = comparemed, aes(shape = star, size = N, color = N)) +
         xlab("OOM PCC Value") + 
         ylab("log(Bayes Factor)") +
         scale_shape_manual(name = "c-Value",
                              labels = c(">.05", "<=.05"),
                              values = c(16,4)) +
        scale_color_grey() +
        labs(title="Medium Effects") +
        scale_x_continuous(labels = numform::ff_num(zero = 0))

pccpnone = ggplot(comparenone, aes(oompcc, omniP)) + 
         cleanup +
         geom_point(data = comparenone, aes(shape = star, size = N, color = N)) +
         xlab("OOM PCC Value") + 
         ylab("p-Value") +
         scale_shape_manual(name = "c-Value",
                              labels = c(">.05", "<=.05"),
                              values = c(16,4)) +
        scale_color_grey() +
        labs(title="Negligible Effects") +
        scale_y_continuous(labels = numform::ff_num(zero = 0)) +
        scale_x_continuous(labels = numform::ff_num(zero = 0))

pccpmed = ggplot(comparemed, aes(oompcc, omniP)) + 
         cleanup +
         geom_point(data = comparemed, aes(shape = star, size = N, color = N)) +
         xlab("OOM PCC Value") + 
         ylab("p-Value") +
         scale_shape_manual(name = "c-Value",
                              labels = c(">.05", "<=.05"),
                              values = c(16,4)) +
        scale_color_grey() +
        labs(title="Medium Effects") +
        scale_y_continuous(labels = numform::ff_num(zero = 0)) +
        scale_x_continuous(labels = numform::ff_num(zero = 0))

pccgraph <- plot_grid( pccbfnone + theme(legend.position="none"),
                   pccpnone + theme(legend.position="none"),
                   pccbfmed + theme(legend.position="none"),
                   pccpmed + theme(legend.position=c(.8,.50)),
                   hjust = -1,
                   nrow = 2)
pccgraph

```

  In Figure \@ref(fig:pcc-bf-fig), the left hand column portrays the relationship between log BF values and PCC values in negligible and medium effect sizes. With negligible effect sizes, we found large variability in PCC values across a small span of BF values while sample sizes remained low, but as *N* increased, we saw that the range of PCC values narrowed considerably with increasing BF values. Therefore, as sample size increased, the PCC values constricted, while BF values expanded. A similar pattern appeared when viewing the medium sample size graph, as again PCC values became less variable with increased sample size, and BF tended to increase both in variability and in value as the sample size grew. Here, we can see a benefit of PCC, along with $c$-values, as increasing sample size portrayed more precision in PCC, instead of the increased variability found in BF. 
 
  It is also important to note that within the negligible effects graph, while many of these PCC values reached high values, that these values did not denote patterns that would necessarily be seen as unique. $c$-values were a secondary measure of evaluation that eliminated a number of these matches from being considered meaningful. A large majority of points with larger sample sizes on the figure included low chance values, however, the PCC values for these simulations were lower than a meaningful percent used for cutoff criterion. This two-step process helped to weed out effects that were negligible, especially at larger sample sizes. 
  
  Additionally, we compared $p$-values and PCC values, which are illustrated on the right hand side of Figure \@ref(fig:pcc-bf-fig). Again, PCC values showed far more variability with small sample sizes, and the $p$-values associated with these smaller sample sizes were also quite variable. Importantly, even when an effect was negligible, PCC values become less variable with increasing sample size. PCC values also indicated that there was little evidence of the hypothesized pattern by shifting toward zero. $p$-values decreased in variability at high sample sizes and shifted toward minuscule values, thus, pointing toward rejecting the null hypothesis. With medium effect sizes, both $p$-values and PCC values were variable at small sample sizes. At larger sample sizes, $p$-values decreased towards floor effects (i.e. closer to zero), while PCC values simply narrowed in range shifting slight above .50. The benefit of multiple criterion evaluation here was clear, as $p$-values indicated significance as sample size increased, while PCC values presented a more stable picture of effect sizes. While multiple criterion may not completely reduce the interpretation of false positives in the literature, the relationship between these values illustrated that multiple indices can provided a clearer picture of the evidentiary value available in a study. 

# Limitations

Within any study a number of limitations exist. The largest limitation of our study is that we chose to focus on a simple three level repeated measures ANOVA design. The benefit to this focus is the simplicity of understanding the relationship between analyses, while also using a well understood NHST procedure. However, is possible that these same relationships may or may not exist in alternative design contexts. Additionally, our choices for classification of significant effects for *p*-values, BF, PCC, and *c*-values was based on what we believe a reasonable researcher may designate; however, these classifications may vary in the real world. We provide open access to our simulations and code so that an interested party can tinker with these choices. We believe the global conclusions would likely be similiar across changes, however, the specific percentages and patterns would likely differ. Finally, due to the specification of our simulation we did not violate any statistical assumptions. It is possible that the violation of these assumptions may cause changes in the relationships we see here.

# Discussion

This manuscript was designed to showcase available methodologies to researchers and to compare the conclusions each methodology might make in a given data environment. We believe that the application of multiple methodologies might assist in strengthening our conclusions and improving reproducibility by giving researchers the ability to weight various forms of evidence. We found that changing the threshold at which *p*-values are deemed significant had little to no effect on conclusions, especially at large sample sizes, regardless of effect size. This finding is notable as the article by @Benjamin2017 states that an increase in sample size is likely to decrease false positives "by factors greater than two" (p. 10), and work by @Pericchi2016 state that an adaptive level of significance would be beneficial in these circumstances, neither of which are not supported by our simulations. Our science will not grow by moving the significance line in the sand, as this line has already been shown to have "no ontological basis" [@Rosnow1989, p. 1277]. 

Instead, we need to embrace the multitude of perspectives available to us and to begin to use a combination of approaches to qualify the strength of evidence. By comparing multiple methodologies, we can see a more nuanced version of our data. Additionally, while all of these methods have limitations, when taken together these methods can begin to overcome these limitations. For instance, given a large sample size, we would expect that BF values to be very large and *p*-values to be very small, both indicating that an effect exists. However, if we also have a PCC value of .40, we may decide that it is possible that this effect is very small and possibly negligible. This multifaceted approach may help to curb our enthusiasm over small or negligible effects that may possibly not replicate. Regardless if analyses agree or disagree on the presence of an effect, a researcher can investigate the size of the effect and discuss conclusions accordingly. Each methodology behaves slightly differently in given data environments, which might begin to highlight meaningful differences when discussed together.  

Some may contest that all of these analyses are capable of being hacked, like *p*-values, through researcher degrees of freedom, choice of priors, or pattern choice, among other actions [@Simmons2011]. Transparency throughout the research process is key to eliminating these issues, as $\alpha$ changes may only encourage bad research practices with the current incentive structure on publishing. Although we have the capability to share research across the world, research often still occurs behind closed doors. The Open Science Framework grants insight into research processes, allowing researchers to share their methodologies, code, design, and other important components of their projects. In addition to posting materials for projects, pre-registration of hypotheses and methodology will be an important facet in scientific accountability. Further, with increased transparency editors and other researchers can weigh the evidence presented according to their own beliefs. 

Our key suggestion in this project is the redefinition of evidentiary value. The current focus on *p*-values has shown to be problematic, as many of the studies from the @OpenScienceCollaboration2015 do not replicate at *p*< .05 or *p* < .005 [@Lakens2017]. With the change in transparency mentioned above, publishing research with solid research designs and statistics, regardless of *p*-values, will allow for a broader range of evidence to become available. Publishing null findings is critical in replication and extension for discovering the limits and settings necessary for phenomena. Registered replications and reports will allow studies to be accepted prior to results being known, thus allowing researchers to focus on experimental design and hypotheses *apriori* instead of *p*-values *post hoc*. Reports should describe multiple indicators of evidence, such as effect sizes, confidence intervals, power analyses, Bayes Factors, and other descriptive statistics [@VantVeer2016; @Nosek2014; @Finkel2015]. 

A misunderstanding of statistical power still plagues psychological sciences [@Bakker2016], and the effect of sample size, especially small ones, was shown here by comparing the criterion avaliable in these analyses. Often, individual research labs may not have the means to adequately power a proposed study. Multilab studies and collaboration with other scientists is fundamental to alleviating these issues, while encouraging interdisciplinary science. Collaboration increases our statistical abilities, as every researcher cannot be expected to be proficient in all methods and analyses, but teams of researchers can be assembled to cover a wider range of statistical skills to provide adequate estimates of evidence in their reports. We understand that there may be resistance to the implementation of multiple methodologies as these new methodologies take time and effort to learn. However, through the use of free programs (JASP, R, OOM, Shiny) and tutorials (YouTube, Coursera, http://www.statstools.com), we believe all researchers are capable of learning these analyses. We believe that through the expansion of our analytical knowledge and application of these new methodologies, we can begin to attenuate some of the strain currently placed on psychological science and to increase the strength of evidence in our discipline.

\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
